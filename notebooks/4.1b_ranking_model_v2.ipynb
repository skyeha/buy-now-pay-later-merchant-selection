{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 12:13:58.997791: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-17 12:13:59.367523: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-17 12:13:59.370160: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-17 12:14:05.832642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.sys.path.append(\"../\")\n",
    "from scripts.ranking_model_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/17 12:14:26 WARN Utils: Your hostname, DESKTOP-H6V94HM resolves to a loopback address: 127.0.1.1; using 192.168.0.220 instead (on interface eth0)\n",
      "24/10/17 12:14:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/17 12:14:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#  Create a Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Ranking Model\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Reading transactions\n",
    "transactions = spark.read.parquet(f\"../data/curated/transactions.parquet\")\n",
    "transactions = transactions.withColumns(\n",
    "    {\"period\": F.date_format(F.col(\"order_datetime\"), \"yyyy-MM\")})\n",
    "transactions = transactions.drop(\"merchant_fp\", \"consumer_fp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading predicted fraud probabilities\n",
    "merchant_fp = spark.read.parquet(f\"../data/curated/predicted_merchant_fp.parquet\")\n",
    "consumer_fp = spark.read.parquet(f\"../data/curated/predicted_consumer_fp.parquet\")\n",
    "\n",
    "# Join with transaction data\n",
    "transactions_full = transactions.join(consumer_fp, on = ['consumer_id', 'order_datetime', 'order_id'], how = 'inner')\n",
    "transactions_full = transactions_full.join(merchant_fp, on = ['merchant_abn', 'order_datetime', 'order_id'], how = 'inner')\n",
    "# transactions_full.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are many ways in ranking the top 100 merchants toi join the BNPL firm, we decided adopted the approach of an investor, consider each merchant as a \"projects\" and evaluating their value. To evluate the merchant's value, we will be using a modified version of **Discounted Cash Flow (DCF)** model where we substitute *cash flow* with *revenue*. The orignal DCF model has the below formula\n",
    "\n",
    "$$ \\text{DCF} = \\sum^{n}_{t=1}\\frac{CF_t}{(1+r)^t}$$\n",
    "\n",
    "where $t$ is the time period of cash flow and $r$ is the discount rate.\n",
    "\n",
    "The DCF model we based on is the one that use **Free Cash Flows (FCF)** from **Earning Before Interest and Tax (EBIT)**. EBIT are usually a percentage of sales revenue and in Corporate Financial Decision Making (FNCE20003), the formula for FCF is defined as\n",
    "\n",
    "$$ \\text{FCF} = \\text{EBIT}(1-t) + \\text{Depreciation} - \\text{Capital Expenditure} - \\Delta\\text{Working Capital}$$\n",
    "\n",
    "Since the BNPL charges merchant per transaction, this means that the firm is charging for a percentage of the sales revenue. Thus, the merchant doesn't pay the BNPL firm through EBIT or their FCF. This allows us to safely consider the percentage of revenue of the merchant as cash flows for the BNPL firm.\n",
    "\n",
    "We will calculate of the project's  DCF using revenues from September 2022, October 2022, and November 2022. The value of the DCF is then multipled by the take rate, which we will called **Expected Project Value (EPV)**. After that, we will assign weights or penalties to the DCF and pick the merchants with the highest DCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data into desried format\n",
    "agg_transactions = transactions_full.groupBy(\"merchant_abn\", \"period\", \"take_rate\").agg(\n",
    "    F.count(F.col(\"order_id\")).alias(\"num_orders\"),\n",
    "    F.round(F.sum(\"dollar_value\"),2).alias('revenue'),\n",
    "    F.round(F.mean(F.col(\"dollar_value\")), 2).alias(\"revenue_per_order\"),\n",
    "    F.round(F.mean(F.col(\"merchant_fp\")), 2).alias(\"avg_merchant_fp\"),\n",
    "    F.round(F.mean(F.col(\"consumer_fp\")), 2).alias(\"avg_consumer_fp\")\n",
    ")\n",
    "\n",
    "agg_transactions = agg_transactions.orderBy([\"merchant_abn\", \"period\"], ascending = [False, True])\n",
    "\n",
    "# Partition the data based on merchant ABN and comput lag variables for each specific partition\n",
    "merchant_partition = Window.partitionBy(\"merchant_abn\").orderBy(\"period\")\n",
    "agg_transactions = agg_transactions.withColumns({\n",
    "    \"revenue_lag_1\": F.lag(\"revenue\", 1, None).over(merchant_partition),\n",
    "    \"revenue_lag_2\": F.lag(\"revenue\", 2, None).over(merchant_partition),\n",
    "    \"revenue_lag_3\": F.lag(\"revenue\", 3, None).over(merchant_partition),\n",
    "    \"num_order_lag_1\": F.lag(\"num_orders\", 1, None).over(merchant_partition),\n",
    "    \"num_order_lag_2\": F.lag(\"num_orders\", 2, None).over(merchant_partition),\n",
    "    \"expected_profit\": F.round(F.col(\"revenue\") * F.col(\"take_rate\")/100,2)\n",
    "    })\n",
    "agg_transactions = agg_transactions.withColumns({\n",
    "    \"revenue_growth\":\n",
    "        F.when(F.col(\"revenue_lag_1\").isNotNull(), F.round((F.col(\"revenue\") - F.col(\"revenue_lag_1\"))/F.col(\"revenue_lag_1\"), 2)).otherwise(None),\n",
    "    \"revenue_growth_lag_1\": F.when(F.col(\"revenue_lag_2\").isNotNull(), \n",
    "        F.round((F.col(\"revenue_lag_1\") - F.col(\"revenue_lag_2\"))/F.col(\"revenue_lag_2\"), 2)).otherwise(None),\n",
    "    \"revenue_growth_lag_2\": F.when(F.col(\"revenue_lag_3\").isNotNull(), \n",
    "        F.round((F.col(\"revenue_lag_2\") - F.col(\"revenue_lag_3\"))/F.col(\"revenue_lag_3\"), 2)).otherwise(None)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing different merchants' values using the DCF model is only reliable when all merchants have revenue in the timeline of interest i.e from May 2021 to August 2022, all merchants must have sales in each month. We noticed that there are some merchants with no revenue in some particular month. Thus, we decide to asume that the missing revenue in some moths of some merchants are totally due to the merchant's inability to make any sales and not because of data entry errors. We adopted the perspective that we want merchants that have consistent sales. We will only consider merchants with 15 months of revenue records, prior to the date of the last transaction entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of merchants with complete sales records: 3212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a dataframe that store the valid date range of the data\n",
    "months = pd.date_range(start=\"2021-06-01\", end=\"2022-08-31\", freq='MS').strftime('%Y-%m').tolist()\n",
    "months_df = spark.createDataFrame([(month,) for month in months], [\"period\"])\n",
    "\n",
    "# Join with the transactions dataframe\n",
    "transactions_correct_months = transactions.join(months_df, on= ['period'], how = 'right')\n",
    "\n",
    "# Get the list of merchants with complete sales records\n",
    "complete_merchants = transactions_correct_months.groupBy(\"merchant_abn\").agg(F.countDistinct(\"period\")\\\n",
    "                                                                             .alias(\"month_count\")).filter(F.col(\"month_count\") == len(months)).select(\"merchant_abn\")\n",
    "print(f\"Number of merchants with complete sales records: {complete_merchants.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the merchants with complete sales records from the aggregated sales \n",
    "# print(f\"Number of entries before removing merchants with missing sales records: {agg_transactions.count()}\")\n",
    "# agg_transactions = agg_transactions.join(complete_merchants, on='merchant_abn', how='inner')\n",
    "# agg_transactions = agg_transactions.filter(\"2021-06\" <= F.col(\"period\")).orderBy(['merchant_abn', 'period'],\n",
    "#                                                                                       ascending = [True, True])\n",
    "# print(f\"Number of entries after removing merchants with missing sales records: {agg_transactions.count()}\")\n",
    "\n",
    "# # Export the aggregated transactions to reduce the need to run this block again\n",
    "# agg_transactions.write.parquet(f\"../data/curated/agg_transactions.parquet\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_transactions = spark.read.parquet(f\"../data/curated/agg_transactions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_transactions_sub = agg_transactions.select(*['merchant_abn', 'period', 'revenue', 'revenue_lag_1', 'revenue_lag_2', 'revenue_lag_3',\n",
    "'revenue_growth_lag_1', 'revenue_growth_lag_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since the last month of sales record is August 2022, this means that we have to forecast the revenues of the next 3 months. We will try 2 different approaches for forecasting revenue of 3 periods into the future. The first approach is to use a simple LSTM to predict the revenue. Contrast to the machine learning nature of approach 1, the second approach will be simply to compute the average monthly revenue growth rate of the 15 months period and then assume that revenues after August 2022 will grow by the same amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for merchant in complete_merchants.rdd.flatMap(lambda x:x).collect():\n",
    "#     # Predict sales revenue 3 period for all valid merchants\n",
    "#     partition = agg_transactions_sub.filter(F.col(\"merchant_abn\") == merchant)\n",
    "    \n",
    "#     forecasted_revenue = forecast_revenue(partition)\n",
    "\n",
    "#     print(forecasted_revenue)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run the above code multiple times, we will see that the forecasted revenues will change with each rerun. This is because the weights between the units are randomly intialise each time and Stochastic Gradient Descent isn't guaranteed to always find the local maximum and minimum. Thus, in order to train a neural network that minimise the mean squared error, we would have to fine-tune our model. The process would be feasible if we're doing for 8-10 merchants. However, our data contains more than 3000 merchants which would be computationally expensive. Thus, we will stick with the second approach that was mentioned previously.\n",
    "\n",
    "Let's aggregate our data and find the monthly average growth for each merchant. From there, we can compute the DCF for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>period</th><th>take_rate</th><th>num_orders</th><th>revenue</th><th>revenue_per_order</th><th>avg_merchant_fp</th><th>avg_consumer_fp</th><th>revenue_lag_1</th><th>revenue_lag_2</th><th>revenue_lag_3</th><th>num_order_lag_1</th><th>num_order_lag_2</th><th>expected_profit</th><th>revenue_growth</th><th>revenue_growth_lag_1</th><th>revenue_growth_lag_2</th></tr>\n",
       "<tr><td>63937753588</td><td>2021-10</td><td>4.17</td><td>14</td><td>42480.29</td><td>3034.31</td><td>41.25</td><td>16.06</td><td>20691.97</td><td>41997.37</td><td>36180.46</td><td>8</td><td>12</td><td>1771.43</td><td>1.05</td><td>-0.51</td><td>0.16</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+-------+---------+----------+--------+-----------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+--------------+--------------------+--------------------+\n",
       "|merchant_abn| period|take_rate|num_orders| revenue|revenue_per_order|avg_merchant_fp|avg_consumer_fp|revenue_lag_1|revenue_lag_2|revenue_lag_3|num_order_lag_1|num_order_lag_2|expected_profit|revenue_growth|revenue_growth_lag_1|revenue_growth_lag_2|\n",
       "+------------+-------+---------+----------+--------+-----------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+--------------+--------------------+--------------------+\n",
       "| 63937753588|2021-10|     4.17|        14|42480.29|          3034.31|          41.25|          16.06|     20691.97|     41997.37|     36180.46|              8|             12|        1771.43|          1.05|               -0.51|                0.16|\n",
       "+------------+-------+---------+----------+--------+-----------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+--------------+--------------------+--------------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_transactions.limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_avg_growth = agg_transactions.groupBy(\"merchant_abn\", ).agg(\n",
    "    F.mean(F.col('revenue_growth')).alias('avg_monthly_revenue_growth'),\n",
    "    F.mean(F.col(\"num_orders\")).alias(\"avg_num_orders\"),\n",
    "    F.mean(F.col(\"revenue_per_order\")).alias('avg_revenue_per_order'),\n",
    "    (F.stddev(F.col('revenue'))/F.mean(F.col('revenue'))).alias(\"coef_of_variation\"),\n",
    "    F.stddev(F.col('revenue_growth')).alias(\"std_reveune_growth\")\n",
    ")\n",
    "merchant_latest_revenue = agg_transactions.filter(F.col(\"period\") == '2022-08').select(\"merchant_abn\", \"revenue\", \"take_rate\")\n",
    "merchant_latest_revenue = merchant_latest_revenue.join(merchant_avg_growth, on ='merchant_abn', how = 'inner')\n",
    "merchant_latest_revenue = merchant_latest_revenue.withColumns({\n",
    "    \"forecasted_revenue_1\": F.col(\"revenue\") * (1 + F.col(\"avg_monthly_revenue_growth\")),\n",
    "    \"forecasted_revenue_2\": F.col(\"revenue\") * (1 + F.col(\"avg_monthly_revenue_growth\"))**2,\n",
    "    \"forecasted_revenue_3\": F.col(\"revenue\") * (1 + F.col(\"avg_monthly_revenue_growth\"))**3,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Victoria State Government [website](https://djsir.vic.gov.au/about-us/overview/the-economic-assessment-information-portal/i-am-looking-for-guidance-on-particular-economic-assessment-processes,-methods-and-variables#:~:text=Department%20of%20Treasury%20and%20Finance,on%20the%20category%20of%20investment.), there is no single discount rate. As a general guideline, the discount rate is between 4% and 7%. We acknowledge that each merchant may have their own discount rates but it's quite extensive to give each and everyone of them an individual discount rate. Thus, we will use the mid point of the recommended range and apply it to all merchants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th></tr>\n",
       "<tr><td>73256306726</td><td>0.02066666666666667</td><td>269.1333333333333</td><td>284.46199999999993</td><td>0.20053707832195655</td><td>0.23998412645919096</td><td>191447.79571678603</td><td>9208.638973977408</td></tr>\n",
       "<tr><td>73841664453</td><td>0.06533333333333333</td><td>47.13333333333333</td><td>86.75933333333334</td><td>0.2788256236984031</td><td>0.26699027983020196</td><td>15736.800264718144</td><td>873.392414691857</td></tr>\n",
       "<tr><td>78916025936</td><td>3.8819999999999992</td><td>3.8</td><td>321.5033333333332</td><td>0.7532806819543889</td><td>12.823639554688496</td><td>291776.5269985978</td><td>1079.5731498948119</td></tr>\n",
       "<tr><td>83412691377</td><td>0.025333333333333333</td><td>727.1333333333333</td><td>34.932</td><td>0.16312759228803875</td><td>0.17307581603227556</td><td>77261.59325069639</td><td>2271.490841570474</td></tr>\n",
       "<tr><td>92202115241</td><td>0.09266666666666667</td><td>5.8</td><td>333.6026666666666</td><td>0.41587657752670437</td><td>0.6025833275711059</td><td>4417.673386814076</td><td>250.04031369367672</td></tr>\n",
       "<tr><td>96946925998</td><td>0.34</td><td>6.0</td><td>924.2446666666666</td><td>0.6041988901065665</td><td>1.3132565846561963</td><td>27450.551701676337</td><td>1644.2880469304125</td></tr>\n",
       "<tr><td>64185141673</td><td>1.1159999999999999</td><td>5.2</td><td>290.19066666666663</td><td>0.6354321269447655</td><td>2.478818266836034</td><td>15163.199259590589</td><td>874.9165972783769</td></tr>\n",
       "<tr><td>66610548417</td><td>0.092</td><td>10.8</td><td>936.6219999999998</td><td>0.2972128564236676</td><td>0.41068235900754246</td><td>39351.835035257325</td><td>2585.4155618164064</td></tr>\n",
       "<tr><td>71002398501</td><td>0.33999999999999997</td><td>6.466666666666667</td><td>326.126</td><td>0.4544716307485942</td><td>1.372630425757161</td><td>7819.599611378878</td><td>295.58086531012157</td></tr>\n",
       "<tr><td>72762528640</td><td>0.25133333333333335</td><td>3.6666666666666665</td><td>273.3106666666667</td><td>0.5389553454598275</td><td>0.9667387493650027</td><td>1296.750849223466</td><td>29.176894107527986</td></tr>\n",
       "<tr><td>87211363921</td><td>0.06000000000000001</td><td>35.13333333333333</td><td>55.967333333333336</td><td>0.3353069504218318</td><td>0.375347458078131</td><td>4872.837716257444</td><td>32.64801269892487</td></tr>\n",
       "<tr><td>68874243493</td><td>0.24133333333333332</td><td>14.266666666666667</td><td>3198.2326666666672</td><td>0.45992313698924436</td><td>0.9829682938257299</td><td>99133.61879431811</td><td>2498.1671936168163</td></tr>\n",
       "<tr><td>80421506936</td><td>0.04733333333333334</td><td>26.666666666666668</td><td>84.776</td><td>0.18529927722569514</td><td>0.215720277431766</td><td>7486.991294832171</td><td>381.8365560364407</td></tr>\n",
       "<tr><td>81583941068</td><td>0.022666666666666665</td><td>191.13333333333333</td><td>298.1940000000001</td><td>0.1870711541709492</td><td>0.20457156158548484</td><td>155520.77665641758</td><td>4727.831610355094</td></tr>\n",
       "<tr><td>86662713230</td><td>0.02533333333333333</td><td>1094.2666666666667</td><td>52.40200000000001</td><td>0.1853516272668784</td><td>0.1852745710200584</td><td>166307.1756759368</td><td>10660.289960827547</td></tr>\n",
       "<tr><td>90568944804</td><td>0.03666666666666667</td><td>541.6</td><td>901.3306666666667</td><td>0.18814575097036243</td><td>0.22843150479071922</td><td>1530233.3272726843</td><td>62739.56641818005</td></tr>\n",
       "<tr><td>98545158925</td><td>0.041999999999999996</td><td>257.73333333333335</td><td>40.972</td><td>0.18931001682279155</td><td>0.21294533168330854</td><td>28202.551190090388</td><td>600.7143403489252</td></tr>\n",
       "<tr><td>63937753588</td><td>0.16133333333333333</td><td>12.0</td><td>2977.2613333333334</td><td>0.3044827841360601</td><td>0.5310618294197641</td><td>135898.61419222382</td><td>5666.972211815733</td></tr>\n",
       "<tr><td>71305424518</td><td>0.05133333333333332</td><td>22.666666666666668</td><td>51.638000000000005</td><td>0.3090333290976863</td><td>0.35411593474185155</td><td>3016.85222147923</td><td>76.0246759812766</td></tr>\n",
       "<tr><td>71649111610</td><td>0.7346666666666664</td><td>8.266666666666667</td><td>289.3773333333333</td><td>0.6942064834299622</td><td>2.3842425172268826</td><td>28174.490597478878</td><td>1214.3205447513394</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order|  coef_of_variation| std_reveune_growth|discounted_revenue_flow|expected_project_value|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+\n",
       "| 73256306726|       0.02066666666666667| 269.1333333333333|   284.46199999999993|0.20053707832195655|0.23998412645919096|     191447.79571678603|     9208.638973977408|\n",
       "| 73841664453|       0.06533333333333333| 47.13333333333333|    86.75933333333334| 0.2788256236984031|0.26699027983020196|     15736.800264718144|      873.392414691857|\n",
       "| 78916025936|        3.8819999999999992|               3.8|    321.5033333333332| 0.7532806819543889| 12.823639554688496|      291776.5269985978|    1079.5731498948119|\n",
       "| 83412691377|      0.025333333333333333| 727.1333333333333|               34.932|0.16312759228803875|0.17307581603227556|      77261.59325069639|     2271.490841570474|\n",
       "| 92202115241|       0.09266666666666667|               5.8|    333.6026666666666|0.41587657752670437| 0.6025833275711059|      4417.673386814076|    250.04031369367672|\n",
       "| 96946925998|                      0.34|               6.0|    924.2446666666666| 0.6041988901065665| 1.3132565846561963|     27450.551701676337|    1644.2880469304125|\n",
       "| 64185141673|        1.1159999999999999|               5.2|   290.19066666666663| 0.6354321269447655|  2.478818266836034|     15163.199259590589|     874.9165972783769|\n",
       "| 66610548417|                     0.092|              10.8|    936.6219999999998| 0.2972128564236676|0.41068235900754246|     39351.835035257325|    2585.4155618164064|\n",
       "| 71002398501|       0.33999999999999997| 6.466666666666667|              326.126| 0.4544716307485942|  1.372630425757161|      7819.599611378878|    295.58086531012157|\n",
       "| 72762528640|       0.25133333333333335|3.6666666666666665|    273.3106666666667| 0.5389553454598275| 0.9667387493650027|      1296.750849223466|    29.176894107527986|\n",
       "| 87211363921|       0.06000000000000001| 35.13333333333333|   55.967333333333336| 0.3353069504218318|  0.375347458078131|      4872.837716257444|     32.64801269892487|\n",
       "| 68874243493|       0.24133333333333332|14.266666666666667|   3198.2326666666672|0.45992313698924436| 0.9829682938257299|      99133.61879431811|    2498.1671936168163|\n",
       "| 80421506936|       0.04733333333333334|26.666666666666668|               84.776|0.18529927722569514|  0.215720277431766|      7486.991294832171|     381.8365560364407|\n",
       "| 81583941068|      0.022666666666666665|191.13333333333333|    298.1940000000001| 0.1870711541709492|0.20457156158548484|     155520.77665641758|     4727.831610355094|\n",
       "| 86662713230|       0.02533333333333333|1094.2666666666667|    52.40200000000001| 0.1853516272668784| 0.1852745710200584|      166307.1756759368|    10660.289960827547|\n",
       "| 90568944804|       0.03666666666666667|             541.6|    901.3306666666667|0.18814575097036243|0.22843150479071922|     1530233.3272726843|     62739.56641818005|\n",
       "| 98545158925|      0.041999999999999996|257.73333333333335|               40.972|0.18931001682279155|0.21294533168330854|     28202.551190090388|     600.7143403489252|\n",
       "| 63937753588|       0.16133333333333333|              12.0|   2977.2613333333334| 0.3044827841360601| 0.5310618294197641|     135898.61419222382|     5666.972211815733|\n",
       "| 71305424518|       0.05133333333333332|22.666666666666668|   51.638000000000005| 0.3090333290976863|0.35411593474185155|       3016.85222147923|      76.0246759812766|\n",
       "| 71649111610|        0.7346666666666664| 8.266666666666667|    289.3773333333333| 0.6942064834299622| 2.3842425172268826|     28174.490597478878|    1214.3205447513394|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_rate = 1.055\n",
    "\n",
    "merchant_latest_revenue = merchant_latest_revenue.withColumns(\n",
    "    {\"discounted_revenue_flow\": F.col(\"forecasted_revenue_1\")/discount_rate + F.col(\"forecasted_revenue_2\")/discount_rate**2 + F.col(\"forecasted_revenue_3\")/discount_rate**3,\n",
    "     \"expected_project_value\": F.col(\"discounted_revenue_flow\") * F.col('take_rate')/100}\n",
    "    )\n",
    "merchant_latest_revenue = merchant_latest_revenue.drop(\"forecasted_revenue_1\", \"forecasted_revenue_2\", \"forecasted_revenue_3\", \"revenue\", \"take_rate\")\n",
    "merchant_latest_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be using the predicted fraud probability for both merchants and consumer as part of our ranking system. We will assign our weights of choice, $\\alpha$ and $\\beta$ to the merchants and consumers' fraud probability, respectively, and sum them. We think that the merchant's fraud probability is more important to the BNPL firm as a merchant with a higher fraud probability with likely to commit scams, thus damaging the BNPL firm's reputation and customer will not shop from the firm anymore. Whereas for customer, it's easier to assess the risk of a customer not paying for the items. Thus, we decided the weight is going to be $\\alpha = 0.65$ and $\\beta = 0.35$. The formula for the combined fraud probability is:\n",
    "\n",
    "$$\\text{Combined Fraud Probability (CBF)} = \\alpha \\times \\text{Merchant's FP} + \\beta\\times\\text{Consumer's FP}$$\n",
    "\n",
    "We will use the combined fraud probability to get the fraud-adjusted DCF\n",
    "\n",
    "$$ \\text{Fraud-adjusted EPV} = (1 - \\text{CBF}) \\times \\text{EPV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fp = agg_transactions.withColumns({\n",
    "    \"total_merchant_fp\": F.col(\"avg_merchant_fp\") * F.col(\"num_orders\"),\n",
    "    \"total_consumer_fp\": F.col(\"avg_consumer_fp\") * F.col(\"num_orders\"),\n",
    "}).select(\"merchant_abn\", \"period\", \"num_orders\", \"total_merchant_fp\", \"total_consumer_fp\")\n",
    "\n",
    "avg_fp = avg_fp.groupBy(\"merchant_abn\").agg(\n",
    "    (F.sum(F.col(\"total_merchant_fp\"))/F.sum(F.col(\"num_orders\"))).alias(\"avg_merchant_fp\"),\n",
    "    (F.sum(F.col(\"total_consumer_fp\"))/F.sum(F.col(\"num_orders\"))).alias(\"avg_consumer_fp\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.65\n",
    "beta = 0.35\n",
    "\n",
    "avg_fp = avg_fp.withColumn(\"combined_fp\", alpha * F.col(\"avg_merchant_fp\") + beta * F.col('avg_consumer_fp'))\n",
    "merchant_ranking_metrics = merchant_latest_revenue.join(avg_fp, on='merchant_abn', how='inner')\n",
    "merchant_ranking_metrics = merchant_ranking_metrics.drop(\"avg_merchant_fp\",\"avg_consumer_fp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_ranking_metrics = merchant_ranking_metrics.withColumn(\n",
    "    \"risk_adjusted_epv\",\n",
    "    F.col(\"expected_project_value\") * (1 - F.col(\"combined_fp\")/100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th><th>combined_fp</th><th>risk_adjusted_epv</th></tr>\n",
       "<tr><td>70344541271</td><td>51.08466666666667</td><td>4.866666666666666</td><td>1081.5886666666665</td><td>0.5737462225685777</td><td>195.37035923989032</td><td>7.229664594670486E8</td><td>4.128138483556847E7</td><td>42.42405479452055</td><td>2.3768147512990005E7</td></tr>\n",
       "<tr><td>71616292306</td><td>27.928666666666665</td><td>2.6666666666666665</td><td>210.442</td><td>0.730322688378949</td><td>106.90505098762485</td><td>5417787.616379169</td><td>177161.6550555988</td><td>39.5622125</td><td>107072.58461398579</td></tr>\n",
       "<tr><td>95276443363</td><td>15.658666666666665</td><td>3.6</td><td>296.6186666666666</td><td>0.6820969976318357</td><td>51.655349033856346</td><td>6601250.027970397</td><td>251507.6260656721</td><td>39.01125925925927</td><td>153391.33400438444</td></tr>\n",
       "<tr><td>75547072158</td><td>12.812666666666667</td><td>3.8666666666666667</td><td>284.17533333333336</td><td>0.7476836101265073</td><td>48.9629811281174</td><td>253224.4641329908</td><td>11445.745778811182</td><td>39.041500000000006</td><td>6977.154940576614</td></tr>\n",
       "<tr><td>12171241826</td><td>10.885333333333334</td><td>8.2</td><td>228.37266666666665</td><td>0.568344026863831</td><td>40.80740511697543</td><td>5073911.329712124</td><td>209552.5379171107</td><td>38.0224756097561</td><td>129875.47529795238</td></tr>\n",
       "<tr><td>33223110337</td><td>10.853333333333333</td><td>2.8</td><td>214.40200000000002</td><td>0.9092808051054941</td><td>38.67401336199554</td><td>463179.7602395222</td><td>21908.402659329404</td><td>38.604011904761904</td><td>13450.880288578708</td></tr>\n",
       "<tr><td>70783350473</td><td>10.031333333333333</td><td>3.066666666666667</td><td>576.6173333333334</td><td>0.5781118668358438</td><td>36.41120272401783</td><td>2314209.098268511</td><td>42812.86831796745</td><td>38.95503260869566</td><td>26135.101503985294</td></tr>\n",
       "<tr><td>52129470223</td><td>9.220000000000002</td><td>4.866666666666666</td><td>309.45399999999995</td><td>0.6017263523053834</td><td>33.47001707285407</td><td>3312653.5794925285</td><td>109317.56812325344</td><td>39.02289726027398</td><td>66658.68582708623</td></tr>\n",
       "<tr><td>33790986203</td><td>7.944</td><td>5.2</td><td>327.7420000000001</td><td>0.6609718021645656</td><td>27.62230615178351</td><td>2327647.7691004816</td><td>140589.9252536691</td><td>41.86257051282051</td><td>81735.3686604302</td></tr>\n",
       "<tr><td>51420872378</td><td>8.786666666666665</td><td>2.8</td><td>258.158</td><td>0.9624601796783046</td><td>23.669936829738464</td><td>30096.247715517915</td><td>990.1665498405393</td><td>38.90971428571428</td><td>604.8955743448707</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+------------------+------------------+-----------------------+----------------------+------------------+--------------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order| coef_of_variation|std_reveune_growth|discounted_revenue_flow|expected_project_value|       combined_fp|   risk_adjusted_epv|\n",
       "+------------+--------------------------+------------------+---------------------+------------------+------------------+-----------------------+----------------------+------------------+--------------------+\n",
       "| 70344541271|         51.08466666666667| 4.866666666666666|   1081.5886666666665|0.5737462225685777|195.37035923989032|    7.229664594670486E8|   4.128138483556847E7| 42.42405479452055|2.3768147512990005E7|\n",
       "| 71616292306|        27.928666666666665|2.6666666666666665|              210.442| 0.730322688378949|106.90505098762485|      5417787.616379169|     177161.6550555988|        39.5622125|  107072.58461398579|\n",
       "| 95276443363|        15.658666666666665|               3.6|    296.6186666666666|0.6820969976318357|51.655349033856346|      6601250.027970397|     251507.6260656721| 39.01125925925927|  153391.33400438444|\n",
       "| 75547072158|        12.812666666666667|3.8666666666666667|   284.17533333333336|0.7476836101265073|  48.9629811281174|      253224.4641329908|    11445.745778811182|39.041500000000006|   6977.154940576614|\n",
       "| 12171241826|        10.885333333333334|               8.2|   228.37266666666665| 0.568344026863831| 40.80740511697543|      5073911.329712124|     209552.5379171107|  38.0224756097561|  129875.47529795238|\n",
       "| 33223110337|        10.853333333333333|               2.8|   214.40200000000002|0.9092808051054941| 38.67401336199554|      463179.7602395222|    21908.402659329404|38.604011904761904|  13450.880288578708|\n",
       "| 70783350473|        10.031333333333333| 3.066666666666667|    576.6173333333334|0.5781118668358438| 36.41120272401783|      2314209.098268511|     42812.86831796745| 38.95503260869566|  26135.101503985294|\n",
       "| 52129470223|         9.220000000000002| 4.866666666666666|   309.45399999999995|0.6017263523053834| 33.47001707285407|     3312653.5794925285|    109317.56812325344| 39.02289726027398|   66658.68582708623|\n",
       "| 33790986203|                     7.944|               5.2|    327.7420000000001|0.6609718021645656| 27.62230615178351|     2327647.7691004816|     140589.9252536691| 41.86257051282051|    81735.3686604302|\n",
       "| 51420872378|         8.786666666666665|               2.8|              258.158|0.9624601796783046|23.669936829738464|     30096.247715517915|     990.1665498405393| 38.90971428571428|   604.8955743448707|\n",
       "+------------+--------------------------+------------------+---------------------+------------------+------------------+-----------------------+----------------------+------------------+--------------------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_ranking_metrics.orderBy(\"std_reveune_growth\", ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we can see that the merchant 1 has a risk-adjusted EPV of approximately $23 millions. This is due to their average monthly revenue growth rate is 5108% which is a massive growth. This is due to fact that this merchant has highly fluctuating monthly revenue growth rate which may affect the average monthly growth rate. Thus, it's important that we penalised merchant with high revenue growth standard deviation. We will use a modified Winsorizor method to remove any standard deviation of revenue growth that are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the intial approach for removing  merchant with unstable revenue growth rate. Double click the cell to view\n",
    "<!-- The formula for calculating the weight is\n",
    "\n",
    "$$W_{\\text{Revenue growth}} = \\frac{1}{\\log (1+s^{\\text{r.g}}_i)} - \\frac{1}{2}$$\n",
    "\n",
    "where $s^{\\text{rev growth}}_i$ is the standard deviation of the merchant's revenue growth rate accross the 15 months period. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lower_bound = merchant_ranking_metrics.select(F.percentile(F.col(\"std_reveune_growth\"), 0.01)).first()[0]\n",
    "upper_bound = merchant_ranking_metrics.select(F.percentile(F.col(\"std_reveune_growth\"), 0.99)).first()[0]\n",
    "\n",
    "merchant_ranking_metrics = merchant_ranking_metrics.filter((lower_bound <= F.col(\"std_reveune_growth\")) & (F.col(\"std_reveune_growth\") <= upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "growth_df = merchant_latest_revenue.select(\"merchant_abn\", \"avg_monthly_revenue_growth\").toPandas()\n",
    "\n",
    "# Scatter plot: Merchants vs Growth Rate\n",
    "df_sorted = growth_df.sort_values(by='avg_monthly_revenue_growth', ascending=False)\n",
    "top_5 = df_sorted.head(5)\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.figure(facecolor='#FDFDFD')\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(growth_df['merchant_abn'], growth_df['avg_monthly_revenue_growth'] * 100, color='#4C91D4', label='All Merchants') # Plot all merchants\n",
    "plt.scatter(top_5['merchant_abn'], top_5['avg_monthly_revenue_growth']* 100, color='#FF6F61', label='Top 5 Merchants') # Highlight the top 5 merchants with red color\n",
    "plt.axhline(30, color='#AD505E', linestyle='dashed', linewidth=2)\n",
    "plt.text(10, 30, \"30%\", color='#AD505E',  fontweight= 'bold')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "for i, row in top_5.iterrows():\n",
    "    plt.annotate(f\"{round(row['avg_monthly_revenue_growth'] *100,2)}\", (row['merchant_abn'], row['avg_monthly_revenue_growth']*100), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xticks([])\n",
    "plt.title(\"Average Monthly Revenue Growth\", fontweight = 'bold', fontsize=14, pad=20)\n",
    "plt.ylabel(\"Growth rate (%)\", fontsize = 12)\n",
    "# plt.savefig(f\"../plots/growth_rate\", transparent = True)\n",
    "plt.savefig(f\"../plots/growth_rate_v2\", transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th><th>combined_fp</th><th>risk_adjusted_epv</th></tr>\n",
       "<tr><td>97884414539</td><td>1.6406666666666667</td><td>3.0</td><td>9981.536666666665</td><td>0.7347099651497621</td><td>4.043104300033871</td><td>1895396.73499406</td><td>129266.05732659489</td><td>44.049511111111116</td><td>72324.99104162121</td></tr>\n",
       "<tr><td>48534649627</td><td>0.025333333333333336</td><td>3335.4666666666667</td><td>143.09733333333332</td><td>0.17851904439502903</td><td>0.1612392484418581</td><td>1400750.4061942906</td><td>93009.82697130089</td><td>30.673439088983052</td><td>64480.51434849038</td></tr>\n",
       "<tr><td>86578477987</td><td>0.026000000000000002</td><td>13805.266666666666</td><td>35.028</td><td>0.17180320536602955</td><td>0.1635236985883086</td><td>1426866.798267028</td><td>91747.5351285699</td><td>30.291424461195973</td><td>63955.89983008991</td></tr>\n",
       "<tr><td>32361057556</td><td>0.025333333333333333</td><td>4341.933333333333</td><td>109.82733333333334</td><td>0.1775619949607971</td><td>0.17058163804494092</td><td>1380419.1374607098</td><td>91245.70498615292</td><td>30.4234067389335</td><td>63485.65302640829</td></tr>\n",
       "<tr><td>45629217853</td><td>0.027333333333333334</td><td>11255.333333333334</td><td>37.83866666666667</td><td>0.18717135892602974</td><td>0.17826411651842677</td><td>1265784.8255556792</td><td>88351.78082378641</td><td>30.81994237694723</td><td>61121.81288488873</td></tr>\n",
       "<tr><td>79827781481</td><td>0.028666666666666667</td><td>241.2</td><td>2036.1873333333338</td><td>0.1758887478875903</td><td>0.18814381530652352</td><td>1417110.0615200887</td><td>96646.90619567005</td><td>38.2490462962963</td><td>59680.386300950144</td></tr>\n",
       "<tr><td>21439773999</td><td>0.024666666666666667</td><td>6118.266666666666</td><td>78.28</td><td>0.17513345558089158</td><td>0.16422400497346243</td><td>1387461.9684095625</td><td>84635.1800729833</td><td>30.246255208446836</td><td>59036.20751198023</td></tr>\n",
       "<tr><td>96680767841</td><td>0.029333333333333333</td><td>1582.3333333333333</td><td>315.58133333333336</td><td>0.1762583893366516</td><td>0.18997994881666053</td><td>1468326.4819790302</td><td>86778.09508496069</td><td>32.35259734569201</td><td>58703.12739786161</td></tr>\n",
       "<tr><td>38700038932</td><td>0.02266666666666666</td><td>365.26666666666665</td><td>1337.1320000000003</td><td>0.17855375493793263</td><td>0.17878425412717286</td><td>1418536.365320908</td><td>89509.64465174929</td><td>34.81062803431283</td><td>58350.77519719366</td></tr>\n",
       "<tr><td>64403598239</td><td>0.025333333333333333</td><td>5752.2</td><td>78.12666666666668</td><td>0.17188020953378486</td><td>0.1548209411207793</td><td>1323501.879621348</td><td>83512.96860410707</td><td>30.271728173568377</td><td>58232.14975859427</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order|  coef_of_variation| std_reveune_growth|discounted_revenue_flow|expected_project_value|       combined_fp| risk_adjusted_epv|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+\n",
       "| 97884414539|        1.6406666666666667|               3.0|    9981.536666666665| 0.7347099651497621|  4.043104300033871|       1895396.73499406|    129266.05732659489|44.049511111111116| 72324.99104162121|\n",
       "| 48534649627|      0.025333333333333336|3335.4666666666667|   143.09733333333332|0.17851904439502903| 0.1612392484418581|     1400750.4061942906|     93009.82697130089|30.673439088983052| 64480.51434849038|\n",
       "| 86578477987|      0.026000000000000002|13805.266666666666|               35.028|0.17180320536602955| 0.1635236985883086|      1426866.798267028|      91747.5351285699|30.291424461195973| 63955.89983008991|\n",
       "| 32361057556|      0.025333333333333333| 4341.933333333333|   109.82733333333334| 0.1775619949607971|0.17058163804494092|     1380419.1374607098|     91245.70498615292|  30.4234067389335| 63485.65302640829|\n",
       "| 45629217853|      0.027333333333333334|11255.333333333334|    37.83866666666667|0.18717135892602974|0.17826411651842677|     1265784.8255556792|     88351.78082378641| 30.81994237694723| 61121.81288488873|\n",
       "| 79827781481|      0.028666666666666667|             241.2|   2036.1873333333338| 0.1758887478875903|0.18814381530652352|     1417110.0615200887|     96646.90619567005|  38.2490462962963|59680.386300950144|\n",
       "| 21439773999|      0.024666666666666667| 6118.266666666666|                78.28|0.17513345558089158|0.16422400497346243|     1387461.9684095625|      84635.1800729833|30.246255208446836| 59036.20751198023|\n",
       "| 96680767841|      0.029333333333333333|1582.3333333333333|   315.58133333333336| 0.1762583893366516|0.18997994881666053|     1468326.4819790302|     86778.09508496069| 32.35259734569201| 58703.12739786161|\n",
       "| 38700038932|       0.02266666666666666|365.26666666666665|   1337.1320000000003|0.17855375493793263|0.17878425412717286|      1418536.365320908|     89509.64465174929| 34.81062803431283| 58350.77519719366|\n",
       "| 64403598239|      0.025333333333333333|            5752.2|    78.12666666666668|0.17188020953378486| 0.1548209411207793|      1323501.879621348|     83512.96860410707|30.271728173568377| 58232.14975859427|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_ranking_metrics.orderBy(\"risk_adjusted_epv\", ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some merchant with a very few amount of orders per month. From the BNPL perspective, we would want merchants with a decent amount of order volume per month as more volume would likely result in more revenue for BNPL firm. We also found that a low average monthly order volume also lead to unstable growth rate, thus, led to unrealistic forecasted revenues. Thus, we need to create a weight that penalises merchant with low order volume. The weight is compute using a Sigmoid function\n",
    "\n",
    "$$ W_{\\text{num orders}} = \\frac{1}{1 + e^{-(\\bar{x_i} - \\bar{x_{.}})}}$$\n",
    "\n",
    "where $\\bar{x_i}$ is the average number of order of merchant $i$ and $\\bar{x_.}$ is the average number of order of all merchants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_order_vol = merchant_latest_revenue.select(\"merchant_abn\", \"avg_num_orders\").toPandas()\n",
    "\n",
    "log_mean_order_volume = np.log(np.mean(avg_order_vol['avg_num_orders']))\n",
    "plt.figure(facecolor='#FDFDFD')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.axvline(np.exp(log_mean_order_volume), color='#AD505E', linestyle='dashed', linewidth=2)\n",
    "_, bins, _ = plt.hist(avg_order_vol['avg_num_orders'], bins=20, color=\"#50AD9F\", edgecolor=\"black\", log=True, alpha=0.5)\n",
    "plt.text(np.exp(log_mean_order_volume + 1.4) , 50, f'{np.exp(log_mean_order_volume):.2f}', color='#AD505E',  fontweight= 'bold',\n",
    "         horizontalalignment='center', verticalalignment='bottom')\n",
    "plt.xticks(bins, rotation=45)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "# plt.savefig(f\"../plots/order_volume\", transparent = True)\n",
    "plt.title(\"Histogram of Order Volume\", fontweight='bold', size=14, pad=20)\n",
    "plt.ylabel(\"Log Frequency\", fontsize = 12)\n",
    "plt.xlabel(\"Order Volume\", fontsize=12)\n",
    "plt.savefig(f\"../plots/order_volume_v2\", transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.6747613117476"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(avg_order_vol['avg_num_orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.359764056546743"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mean_order_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.6747613117476"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute average monthly order volume of all merchants\n",
    "mean_num_orders = agg_transactions.agg(F.mean(\"num_orders\")).collect()[0][0]\n",
    "mean_num_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th><th>combined_fp</th><th>risk_adjusted_epv</th></tr>\n",
       "<tr><td>48534649627</td><td>0.025333333333333336</td><td>3335.4666666666667</td><td>143.09733333333332</td><td>0.17851904439502903</td><td>0.1612392484418581</td><td>1400750.4061942906</td><td>93009.82697130089</td><td>30.673439088983052</td><td>64480.51434849038</td></tr>\n",
       "<tr><td>86578477987</td><td>0.026000000000000002</td><td>13805.266666666666</td><td>35.028</td><td>0.17180320536602955</td><td>0.1635236985883086</td><td>1426866.798267028</td><td>91747.5351285699</td><td>30.291424461195973</td><td>63955.89983008991</td></tr>\n",
       "<tr><td>32361057556</td><td>0.025333333333333333</td><td>4341.933333333333</td><td>109.82733333333334</td><td>0.1775619949607971</td><td>0.17058163804494092</td><td>1380419.1374607098</td><td>91245.70498615292</td><td>30.4234067389335</td><td>63485.65302640829</td></tr>\n",
       "<tr><td>45629217853</td><td>0.027333333333333334</td><td>11255.333333333334</td><td>37.83866666666667</td><td>0.18717135892602974</td><td>0.17826411651842677</td><td>1265784.8255556792</td><td>88351.78082378641</td><td>30.81994237694723</td><td>61121.81288488873</td></tr>\n",
       "<tr><td>79827781481</td><td>0.028666666666666667</td><td>241.2</td><td>2036.1873333333338</td><td>0.1758887478875903</td><td>0.18814381530652352</td><td>1417110.0615200887</td><td>96646.90619567005</td><td>38.2490462962963</td><td>59680.38630092573</td></tr>\n",
       "<tr><td>21439773999</td><td>0.024666666666666667</td><td>6118.266666666666</td><td>78.28</td><td>0.17513345558089158</td><td>0.16422400497346243</td><td>1387461.9684095625</td><td>84635.1800729833</td><td>30.246255208446836</td><td>59036.20751198023</td></tr>\n",
       "<tr><td>96680767841</td><td>0.029333333333333333</td><td>1582.3333333333333</td><td>315.58133333333336</td><td>0.1762583893366516</td><td>0.18997994881666053</td><td>1468326.4819790302</td><td>86778.09508496069</td><td>32.35259734569201</td><td>58703.12739786161</td></tr>\n",
       "<tr><td>38700038932</td><td>0.02266666666666666</td><td>365.26666666666665</td><td>1337.1320000000003</td><td>0.17855375493793263</td><td>0.17878425412717286</td><td>1418536.365320908</td><td>89509.64465174929</td><td>34.81062803431283</td><td>58350.77519719366</td></tr>\n",
       "<tr><td>64403598239</td><td>0.025333333333333333</td><td>5752.2</td><td>78.12666666666668</td><td>0.17188020953378486</td><td>0.1548209411207793</td><td>1323501.879621348</td><td>83512.96860410707</td><td>30.271728173568377</td><td>58232.14975859427</td></tr>\n",
       "<tr><td>89726005175</td><td>0.026</td><td>10937.533333333333</td><td>41.28066666666666</td><td>0.17785400363988527</td><td>0.1696551123392901</td><td>1346359.9274887978</td><td>80916.23164207675</td><td>30.303525237256423</td><td>56395.76096538315</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+-----------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order|  coef_of_variation| std_reveune_growth|discounted_revenue_flow|expected_project_value|       combined_fp|risk_adjusted_epv|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+-----------------+\n",
       "| 48534649627|      0.025333333333333336|3335.4666666666667|   143.09733333333332|0.17851904439502903| 0.1612392484418581|     1400750.4061942906|     93009.82697130089|30.673439088983052|64480.51434849038|\n",
       "| 86578477987|      0.026000000000000002|13805.266666666666|               35.028|0.17180320536602955| 0.1635236985883086|      1426866.798267028|      91747.5351285699|30.291424461195973|63955.89983008991|\n",
       "| 32361057556|      0.025333333333333333| 4341.933333333333|   109.82733333333334| 0.1775619949607971|0.17058163804494092|     1380419.1374607098|     91245.70498615292|  30.4234067389335|63485.65302640829|\n",
       "| 45629217853|      0.027333333333333334|11255.333333333334|    37.83866666666667|0.18717135892602974|0.17826411651842677|     1265784.8255556792|     88351.78082378641| 30.81994237694723|61121.81288488873|\n",
       "| 79827781481|      0.028666666666666667|             241.2|   2036.1873333333338| 0.1758887478875903|0.18814381530652352|     1417110.0615200887|     96646.90619567005|  38.2490462962963|59680.38630092573|\n",
       "| 21439773999|      0.024666666666666667| 6118.266666666666|                78.28|0.17513345558089158|0.16422400497346243|     1387461.9684095625|      84635.1800729833|30.246255208446836|59036.20751198023|\n",
       "| 96680767841|      0.029333333333333333|1582.3333333333333|   315.58133333333336| 0.1762583893366516|0.18997994881666053|     1468326.4819790302|     86778.09508496069| 32.35259734569201|58703.12739786161|\n",
       "| 38700038932|       0.02266666666666666|365.26666666666665|   1337.1320000000003|0.17855375493793263|0.17878425412717286|      1418536.365320908|     89509.64465174929| 34.81062803431283|58350.77519719366|\n",
       "| 64403598239|      0.025333333333333333|            5752.2|    78.12666666666668|0.17188020953378486| 0.1548209411207793|      1323501.879621348|     83512.96860410707|30.271728173568377|58232.14975859427|\n",
       "| 89726005175|                     0.026|10937.533333333333|    41.28066666666666|0.17785400363988527| 0.1696551123392901|     1346359.9274887978|     80916.23164207675|30.303525237256423|56395.76096538315|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+-----------------+"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_ranking_metrics = merchant_ranking_metrics.withColumn(\"risk_adjusted_epv\", F.col(\"risk_adjusted_epv\") * (1/(1 + F.exp(-F.col(\"avg_num_orders\"))*np.exp(mean_num_orders))))\n",
    "merchant_ranking_metrics.orderBy(\"risk_adjusted_epv\", ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **coefficient of variation** is a ratio between the standard deviation and the mean, measuring the relative stability which help us compare merchants with different average revenue. Thus, we will create a weight that favors merchant with higher stability. The weight is calculate as\n",
    "\n",
    "$$W_{\\text{CV}} = \\frac{1}{1 + CV}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th><th>combined_fp</th><th>risk_adjusted_epv</th></tr>\n",
       "<tr><td>48534649627</td><td>0.025333333333333336</td><td>3335.4666666666667</td><td>143.09733333333332</td><td>0.17851904439502903</td><td>0.1612392484418581</td><td>1400750.4061942906</td><td>93009.82697130089</td><td>30.673439088983052</td><td>54713.17129337545</td></tr>\n",
       "<tr><td>86578477987</td><td>0.026000000000000002</td><td>13805.266666666666</td><td>35.028</td><td>0.17180320536602955</td><td>0.1635236985883086</td><td>1426866.798267028</td><td>91747.5351285699</td><td>30.291424461195973</td><td>54579.04496012397</td></tr>\n",
       "<tr><td>32361057556</td><td>0.025333333333333333</td><td>4341.933333333333</td><td>109.82733333333334</td><td>0.1775619949607971</td><td>0.17058163804494092</td><td>1380419.1374607098</td><td>91245.70498615292</td><td>30.4234067389335</td><td>53912.79040771167</td></tr>\n",
       "<tr><td>45629217853</td><td>0.027333333333333334</td><td>11255.333333333334</td><td>37.83866666666667</td><td>0.18717135892602974</td><td>0.17826411651842677</td><td>1265784.8255556792</td><td>88351.78082378641</td><td>30.81994237694723</td><td>51485.24888621164</td></tr>\n",
       "<tr><td>79827781481</td><td>0.028666666666666667</td><td>241.2</td><td>2036.1873333333338</td><td>0.1758887478875903</td><td>0.18814381530652352</td><td>1417110.0615200887</td><td>96646.90619567005</td><td>38.2490462962963</td><td>50753.42918974075</td></tr>\n",
       "<tr><td>21439773999</td><td>0.024666666666666667</td><td>6118.266666666666</td><td>78.28</td><td>0.17513345558089158</td><td>0.16422400497346243</td><td>1387461.9684095625</td><td>84635.1800729833</td><td>30.246255208446836</td><td>50237.87488272766</td></tr>\n",
       "<tr><td>96680767841</td><td>0.029333333333333333</td><td>1582.3333333333333</td><td>315.58133333333336</td><td>0.1762583893366516</td><td>0.18997994881666053</td><td>1468326.4819790302</td><td>86778.09508496069</td><td>32.35259734569201</td><td>49906.659905709246</td></tr>\n",
       "<tr><td>64403598239</td><td>0.025333333333333333</td><td>5752.2</td><td>78.12666666666668</td><td>0.17188020953378486</td><td>0.1548209411207793</td><td>1323501.879621348</td><td>83512.96860410707</td><td>30.271728173568377</td><td>49691.21355992612</td></tr>\n",
       "<tr><td>38700038932</td><td>0.02266666666666666</td><td>365.26666666666665</td><td>1337.1320000000003</td><td>0.17855375493793263</td><td>0.17878425412717286</td><td>1418536.365320908</td><td>89509.64465174929</td><td>34.81062803431283</td><td>49510.49110209373</td></tr>\n",
       "<tr><td>89726005175</td><td>0.026</td><td>10937.533333333333</td><td>41.28066666666666</td><td>0.17785400363988527</td><td>0.1696551123392901</td><td>1346359.9274887978</td><td>80916.23164207675</td><td>30.303525237256423</td><td>47880.09446935283</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order|  coef_of_variation| std_reveune_growth|discounted_revenue_flow|expected_project_value|       combined_fp| risk_adjusted_epv|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+\n",
       "| 48534649627|      0.025333333333333336|3335.4666666666667|   143.09733333333332|0.17851904439502903| 0.1612392484418581|     1400750.4061942906|     93009.82697130089|30.673439088983052| 54713.17129337545|\n",
       "| 86578477987|      0.026000000000000002|13805.266666666666|               35.028|0.17180320536602955| 0.1635236985883086|      1426866.798267028|      91747.5351285699|30.291424461195973| 54579.04496012397|\n",
       "| 32361057556|      0.025333333333333333| 4341.933333333333|   109.82733333333334| 0.1775619949607971|0.17058163804494092|     1380419.1374607098|     91245.70498615292|  30.4234067389335| 53912.79040771167|\n",
       "| 45629217853|      0.027333333333333334|11255.333333333334|    37.83866666666667|0.18717135892602974|0.17826411651842677|     1265784.8255556792|     88351.78082378641| 30.81994237694723| 51485.24888621164|\n",
       "| 79827781481|      0.028666666666666667|             241.2|   2036.1873333333338| 0.1758887478875903|0.18814381530652352|     1417110.0615200887|     96646.90619567005|  38.2490462962963| 50753.42918974075|\n",
       "| 21439773999|      0.024666666666666667| 6118.266666666666|                78.28|0.17513345558089158|0.16422400497346243|     1387461.9684095625|      84635.1800729833|30.246255208446836| 50237.87488272766|\n",
       "| 96680767841|      0.029333333333333333|1582.3333333333333|   315.58133333333336| 0.1762583893366516|0.18997994881666053|     1468326.4819790302|     86778.09508496069| 32.35259734569201|49906.659905709246|\n",
       "| 64403598239|      0.025333333333333333|            5752.2|    78.12666666666668|0.17188020953378486| 0.1548209411207793|      1323501.879621348|     83512.96860410707|30.271728173568377| 49691.21355992612|\n",
       "| 38700038932|       0.02266666666666666|365.26666666666665|   1337.1320000000003|0.17855375493793263|0.17878425412717286|      1418536.365320908|     89509.64465174929| 34.81062803431283| 49510.49110209373|\n",
       "| 89726005175|                     0.026|10937.533333333333|    41.28066666666666|0.17785400363988527| 0.1696551123392901|     1346359.9274887978|     80916.23164207675|30.303525237256423| 47880.09446935283|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_ranking_metrics = merchant_ranking_metrics.withColumn(\"risk_adjusted_epv\", F.col(\"risk_adjusted_epv\") * (1/(1 + F.col(\"coef_of_variation\") )))\n",
    "merchant_ranking_metrics.orderBy(\"risk_adjusted_epv\", ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the adjusted EPV that accounts for different factor, we can now merge the merchants to their respective segments and will select top 20 merchants from each segnment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+--------------------------------------+-------------------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv     |name                                  |segments                                         |\n",
      "+------------+----------------------+--------------------------------------+-------------------------------------------------+\n",
      "|73256306726 |5106.3445582384       |Id LLP                                |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|73841664453 |5.079036435468569E-70 |Lacinia At LLP                        |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "|83412691377 |1405.0444371658846    |Suspendisse Sagittis Nullam Associates|Fashion, Personal Accessories, Health, and Beauty|\n",
      "|92202115241 |1.4102977797408417E-88|Fames Ac Turpis Limited               |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "|96946925998 |1.0739640028656378E-87|Nisi Cum Corporation                  |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "|64185141673 |2.3941758416049687E-88|Maecenas Corp.                        |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "|66610548417 |2.4996015505912874E-85|Nulla Inc.                            |Vehicles, Repairs, and Miscellaneous Services    |\n",
      "|71002398501 |3.3941808635930086E-88|Ipsum Phasellus Corp.                 |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|72762528640 |1.9403629120087297E-90|Sit Amet Risus Associates             |Vehicles, Repairs, and Miscellaneous Services    |\n",
      "|87211363921 |1.0379429906229265E-76|Mauris Non PC                         |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "+------------+----------------------+--------------------------------------+-------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading in the segmented merchants\n",
    "segments = spark.read.parquet(f\"../data/curated/segmented_merchants_info.parquet/\")\n",
    "segments = segments.select(\"name\", \"merchant_abn\", \"segments\")\n",
    "\n",
    "complete_ranking = merchant_ranking_metrics.select(\"merchant_abn\", \"risk_adjusted_epv\")\n",
    "\n",
    "# Merge ranking with segments\n",
    "complete_ranking = complete_ranking.join(segments, on = 'merchant_abn', how='inner')\n",
    "complete_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_segments = complete_ranking.groupBy(\"segments\").agg(F.count(\"merchant_abn\").alias('num_merchants')).orderBy(\"num_merchants\", ascending = False)\n",
    "grouped_segments_pd = grouped_segments.toPandas()\n",
    "colours = [\"#f7b03e\", \"#4c91d4\", \"#a265a8\", \"#27ae60\" ,\"#cb4760\"]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.pie(grouped_segments_pd['num_merchants'], colors=colours, wedgeprops=dict(width=0.5), startangle=-40, explode= [0.05]*5, labels=grouped_segments_pd['segments'])\n",
    "plt.savefig(f\"../plots/donut_chart_segments\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_value_segments = complete_ranking.groupBy(\"segments\").agg(F.sum(\"risk_adjusted_epv\").alias(\"total_epv\")).orderBy(\"total_epv\", ascending=False)\n",
    "total_value_segments_pd = total_value_segments.toPandas()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "bars= plt.bar(total_value_segments_pd['segments'], total_value_segments_pd['total_epv'], color = colours, edgecolor = 'black')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.yticks(size=14)\n",
    "plt.xticks([])\n",
    "plt.legend(bars, total_value_segments_pd['segments'], fontsize=14)\n",
    "plt.title(\"Total Estimated Revenue of each Segments\", fontsize=16, fontweight='bold',\n",
    "          pad=20)\n",
    "plt.ylabel(\"Dollar ($)\")\n",
    "# plt.savefig(f'../plots/total_revenue_segments', transparent = True)\n",
    "plt.savefig(f'../plots/total_revenue_segments_v2', transparent = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segments</th>\n",
       "      <th>total_epv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Books, Media, Arts, Crafts, and Hobbies</td>\n",
       "      <td>1.419670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computers, Electronics, and Office Supplies</td>\n",
       "      <td>9.237914e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vehicles, Repairs, and Miscellaneous Services</td>\n",
       "      <td>8.031290e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fashion, Personal Accessories, Health, and Beauty</td>\n",
       "      <td>7.351826e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home, Garden, and Furnishings</td>\n",
       "      <td>6.485205e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            segments     total_epv\n",
       "0            Books, Media, Arts, Crafts, and Hobbies  1.419670e+06\n",
       "1        Computers, Electronics, and Office Supplies  9.237914e+05\n",
       "2      Vehicles, Repairs, and Miscellaneous Services  8.031290e+05\n",
       "3  Fashion, Personal Accessories, Health, and Beauty  7.351826e+05\n",
       "4                      Home, Garden, and Furnishings  6.485205e+05"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:16:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:16:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:16:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:16:27 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n",
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 51458)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/skyeha/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/skyeha/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/home/skyeha/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/skyeha/.local/lib/python3.8/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "total_value_segments_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [\"Computers, Electronics, and Office Supplies\", \"Home, Garden, and Furnishings\", \"Books, Media, Arts, Crafts, and Hobbies\", \"Fashion, Personal Accessories, Health, and Beauty\"\n",
    "            , \"Vehicles, Repairs, and Miscellaneous Services\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----------------------------+-------------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                         |segments                                   |\n",
      "+------------+------------------+-----------------------------+-------------------------------------------+\n",
      "|21439773999 |50237.87488272766 |Mauris Non Institute         |Computers, Electronics, and Office Supplies|\n",
      "|82368304209 |47340.66112303206 |Nec Incorporated             |Computers, Electronics, and Office Supplies|\n",
      "|35909341340 |40682.22831221837 |Arcu Sed Eu Incorporated     |Computers, Electronics, and Office Supplies|\n",
      "|45433476494 |36275.68139853707 |Adipiscing Elit Foundation   |Computers, Electronics, and Office Supplies|\n",
      "|58454491168 |35154.509483312075|Diam At Foundation           |Computers, Electronics, and Office Supplies|\n",
      "|94690988633 |34267.85544270964 |Eu Placerat LLC              |Computers, Electronics, and Office Supplies|\n",
      "|67400260923 |28740.143895221187|Eleifend PC                  |Computers, Electronics, and Office Supplies|\n",
      "|80518954462 |28358.23050269475 |Neque Sed Dictum Incorporated|Computers, Electronics, and Office Supplies|\n",
      "|57757792876 |26740.83898664496 |Pretium Et LLC               |Computers, Electronics, and Office Supplies|\n",
      "|34096466752 |26526.128306872553|Nullam Enim Ltd              |Computers, Electronics, and Office Supplies|\n",
      "+------------+------------------+-----------------------------+-------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seg1_ranking = complete_ranking.filter(F.col('segments') == segments[0])\n",
    "seg1_ranking = seg1_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg1_ranking.write.parquet(f\"../data/curated/seg1_ranking.parquet\", mode='overwrite')\n",
    "seg1_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------------------+-----------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                          |segments                     |\n",
      "+------------+------------------+------------------------------+-----------------------------+\n",
      "|79827781481 |50753.42918974075 |Amet Risus Inc.               |Home, Garden, and Furnishings|\n",
      "|76767266140 |39744.37216363429 |Phasellus At Limited          |Home, Garden, and Furnishings|\n",
      "|43186523025 |37023.390424610785|Lorem Ipsum Sodales Industries|Home, Garden, and Furnishings|\n",
      "|49212265466 |32280.258727887383|Auctor Company                |Home, Garden, and Furnishings|\n",
      "|21772962346 |29226.73924604561 |Purus Gravida Sagittis Ltd    |Home, Garden, and Furnishings|\n",
      "|38090089066 |26982.619960897013|Interdum Feugiat Sed Inc.     |Home, Garden, and Furnishings|\n",
      "|42355028515 |26876.88514332147 |Eu Inc.                       |Home, Garden, and Furnishings|\n",
      "|76314317957 |26000.036184292283|Semper Corp.                  |Home, Garden, and Furnishings|\n",
      "|24852446429 |23186.20228093389 |Erat Vitae LLP                |Home, Garden, and Furnishings|\n",
      "|90543168331 |20781.929508536887|Phasellus Dapibus Incorporated|Home, Garden, and Furnishings|\n",
      "+------------+------------------+------------------------------+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "seg2_ranking = complete_ranking.filter(F.col('segments') == segments[1])\n",
    "seg2_ranking = seg2_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg2_ranking.write.parquet(f\"../data/curated/seg2_ranking.parquet\", mode='overwrite')\n",
    "seg2_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----------------------------+---------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                         |segments                               |\n",
      "+------------+------------------+-----------------------------+---------------------------------------+\n",
      "|32361057556 |53912.79040771167 |Orci In Consequat Corporation|Books, Media, Arts, Crafts, and Hobbies|\n",
      "|45629217853 |51485.24888621164 |Lacus Consulting             |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|64403598239 |49691.21355992612 |Lobortis Ultrices Company    |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|94493496784 |44891.043232800184|Dictum Phasellus In Institute|Books, Media, Arts, Crafts, and Hobbies|\n",
      "|63123845164 |44701.43692027049 |Odio Phasellus Institute     |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|72472909171 |40469.11957641558 |Nullam Consulting            |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|79417999332 |40427.97266394555 |Phasellus At Company         |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|40515428545 |40112.4793529307  |Elit Sed Consequat Associates|Books, Media, Arts, Crafts, and Hobbies|\n",
      "|27326652377 |38748.743017667766|Tellus Aenean Corporation    |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|98973094975 |36338.63267471447 |Ornare Fusce Inc.            |Books, Media, Arts, Crafts, and Hobbies|\n",
      "+------------+------------------+-----------------------------+---------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "seg3_ranking = complete_ranking.filter(F.col('segments') == segments[2])\n",
    "seg3_ranking = seg3_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg3_ranking.write.parquet(f\"../data/curated/seg3_ranking.parquet\", mode='overwrite')\n",
    "seg3_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----------------------------+-------------------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                         |segments                                         |\n",
      "+------------+------------------+-----------------------------+-------------------------------------------------+\n",
      "|48534649627 |54713.17129337545 |Dignissim Maecenas Foundation|Fashion, Personal Accessories, Health, and Beauty|\n",
      "|86578477987 |54579.04496012397 |Leo In Consulting            |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|49322182190 |45390.3585100905  |Gravida Mauris Incorporated  |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|93558142492 |27957.937277723926|Dolor Quisque Inc.           |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|11439466003 |24345.4354053516  |Blandit At LLC               |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|95574756848 |21336.60624685837 |At Pede Inc.                 |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|99976658299 |19586.089687544805|Sociosqu Corp.               |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|62224020443 |18998.98769599394 |Hendrerit A Corporation      |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|46804135891 |18890.05620563631 |Suspendisse Dui Corporation  |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|81761494572 |17862.539408761997|Nulla Facilisis Institute    |Fashion, Personal Accessories, Health, and Beauty|\n",
      "+------------+------------------+-----------------------------+-------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seg4_ranking = complete_ranking.filter(F.col('segments') == segments[3])\n",
    "seg4_ranking = seg4_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg4_ranking.write.parquet(f\"../data/curated/seg4_ranking.parquet\", mode='overwrite')\n",
    "seg4_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 840:>                (0 + 3) / 3][Stage 843:>                (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------------------+---------------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                          |segments                                     |\n",
      "+------------+------------------+------------------------------+---------------------------------------------+\n",
      "|96680767841 |49906.659905709246|Ornare Limited                |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|38700038932 |49510.49110209373 |Etiam Bibendum Industries     |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|89726005175 |47880.09446935283 |Est Nunc Consulting           |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|80551528183 |37912.869172420076|Ac Ipsum LLC                  |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|49891706470 |36535.65054086117 |Non Vestibulum Industries     |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|90568944804 |35928.5012315087  |Diam Eu Dolor LLC             |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|13514558491 |35267.10118083442 |Magna Praesent PC             |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|75454398468 |32470.586703261   |Tempus Non Lacinia Corporation|Vehicles, Repairs, and Miscellaneous Services|\n",
      "|68559320474 |29984.835543031975|Aliquam Auctor Associates     |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|49549583265 |29787.8818223957  |Luctus Et Incorporated        |Vehicles, Repairs, and Miscellaneous Services|\n",
      "+------------+------------------+------------------------------+---------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "seg5_ranking = complete_ranking.filter(F.col('segments') == segments[4])\n",
    "seg5_ranking = seg5_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg5_ranking.write.parquet(f\"../data/curated/seg5_ranking.parquet\", mode='overwrite')\n",
    "seg5_ranking.show(10, truncate = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
