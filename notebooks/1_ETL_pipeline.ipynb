{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Loading library\n",
                        "import os\n",
                        "os.sys.path.append(\"../\")\n",
                        "from scripts.etl_pipeline import *"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "24/10/16 14:48:12 WARN Utils: Your hostname, DESKTOP-H6V94HM resolves to a loopback address: 127.0.1.1; using 192.168.0.220 instead (on interface eth0)\n",
                                    "24/10/16 14:48:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
                                    "Setting default log level to \"WARN\".\n",
                                    "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
                                    "24/10/16 14:48:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Create a Spark Session\n",
                        "spark = (\n",
                        "    SparkSession.builder.appName(\"ETL Pipeline\")\n",
                        "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
                        "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
                        "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
                        "    .config(\"spark.driver.memory\", \"4g\")\n",
                        "    .config(\"spark.executor.memory\", \"2g\")\n",
                        "    .getOrCreate()\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "# Extract"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## BNPL Dataset"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "As we can't use `urlretrieve` to get the data from Canvas, please download it to your local machine and move it `data/tables`. Then run the code below to unzip the files"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "'\\nfor file in os.listdir(f\"{raw_path}/tables\"):\\n    if file == \".gitkeep\":\\n        continue\\n    with zipfile.ZipFile(f\"{raw_path}/tables/{file}\", \"r\") as zip_ref:\\n        zip_ref.extractall(f\"{raw_path}/\")\\n    os.remove(f\"{raw_path}/tables/{file}\")\\n'"
                                    ]
                              },
                              "execution_count": 3,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "# Assign data path\n",
                        "raw_path = \"../data\"\n",
                        "\n",
                        "# Unzip files (Only run once)\n",
                        "\"\"\"\n",
                        "for file in os.listdir(f\"{raw_path}/tables\"):\n",
                        "    if file == \".gitkeep\":\n",
                        "        continue\n",
                        "    with zipfile.ZipFile(f\"{raw_path}/tables/{file}\", \"r\") as zip_ref:\n",
                        "        zip_ref.extractall(f\"{raw_path}/\")\n",
                        "    os.remove(f\"{raw_path}/tables/{file}\")\n",
                        "\"\"\""
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## External Dataset"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Our external dataset will include socio-economic as well as demographics data on different granularity levels such as state and Local Government Area (LGA), collected from the Australia's Bureau of Statistic. Since LGA is a region that includes postcodes and suburbs, we found a dataset that help us map postcode to LGA code. We downloaded the data that maps postcode to LGA code directly as the website doesn't allow us to use `urlretrieve`. The data can be downloaded by clicking [here](https://www.matthewproctor.com/Content/postcodes/australian_postcodes.csv)."
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "We will also use the ABS's **Personal Income in Australia** for each LGA region"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "('../data/raw/income_data.xlsx', <http.client.HTTPMessage at 0x7fad1eff3d60>)"
                                    ]
                              },
                              "execution_count": 4,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "INCOME_DATA_URL = \"https://www.abs.gov.au/statistics/labour/earnings-and-working-conditions/personal-income-australia/2020-21-financial-year/Table%202%20-%20Total%20income%20distribution%20by%20geography%2C%202020-21.xlsx\"\n",
                        "\n",
                        "urlretrieve(INCOME_DATA_URL, f\"{raw_path}/raw/income_data.xlsx\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Getting the ABS's **Personal Fraud** statistics, which includes card fraud, identity theft, and scams."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "('../data/raw/personal_fraud.xlsx',\n",
                                          " <http.client.HTTPMessage at 0x7fad1f1b75b0>)"
                                    ]
                              },
                              "execution_count": 5,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "PERSONAL_FRAUD_DATA_URL = \"https://www.abs.gov.au/statistics/people/crime-and-justice/personal-fraud/2022-23/Personal%20Fraud%20%28Tables%201a%20to%2014b%29.xlsx\"\n",
                        "\n",
                        "urlretrieve(PERSONAL_FRAUD_DATA_URL, f\"{raw_path}/raw/personal_fraud.xlsx\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "# Transform\n",
                        "\n",
                        "## External Dataset\n",
                        "\n",
                        "For the data on mapping postcodes to LGA code, we will only select the columns that are neccessary for the mapping. There are some entries with missing LGA code. To resolve this, we will use the closest postcode, using lattitude and longitude, and if it has a valid LGA code, we will impute the missing value with the existing one. To do this, we will using K-Nearest Neighour wth `k=1` to do. The reason being the data is already being sorted (clustered) using states. Thus, we only need to select the closest postcode with a valid LGA to the target.\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/html": [
                                          "<div>\n",
                                          "<style scoped>\n",
                                          "    .dataframe tbody tr th:only-of-type {\n",
                                          "        vertical-align: middle;\n",
                                          "    }\n",
                                          "\n",
                                          "    .dataframe tbody tr th {\n",
                                          "        vertical-align: top;\n",
                                          "    }\n",
                                          "\n",
                                          "    .dataframe thead th {\n",
                                          "        text-align: right;\n",
                                          "    }\n",
                                          "</style>\n",
                                          "<table border=\"1\" class=\"dataframe\">\n",
                                          "  <thead>\n",
                                          "    <tr style=\"text-align: right;\">\n",
                                          "      <th></th>\n",
                                          "      <th>postcode</th>\n",
                                          "      <th>state</th>\n",
                                          "      <th>long</th>\n",
                                          "      <th>lat</th>\n",
                                          "      <th>lgacode</th>\n",
                                          "    </tr>\n",
                                          "  </thead>\n",
                                          "  <tbody>\n",
                                          "    <tr>\n",
                                          "      <th>0</th>\n",
                                          "      <td>200</td>\n",
                                          "      <td>ACT</td>\n",
                                          "      <td>149.119000</td>\n",
                                          "      <td>-35.277700</td>\n",
                                          "      <td>89399</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>2</th>\n",
                                          "      <td>800</td>\n",
                                          "      <td>NT</td>\n",
                                          "      <td>130.836680</td>\n",
                                          "      <td>-12.458684</td>\n",
                                          "      <td>71150</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>4</th>\n",
                                          "      <td>801</td>\n",
                                          "      <td>NT</td>\n",
                                          "      <td>130.836680</td>\n",
                                          "      <td>-12.458684</td>\n",
                                          "      <td>71000</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>5</th>\n",
                                          "      <td>803</td>\n",
                                          "      <td>NT</td>\n",
                                          "      <td>130.745908</td>\n",
                                          "      <td>-12.433991</td>\n",
                                          "      <td>71000</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>6</th>\n",
                                          "      <td>804</td>\n",
                                          "      <td>NT</td>\n",
                                          "      <td>130.873315</td>\n",
                                          "      <td>-12.428017</td>\n",
                                          "      <td>71000</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>...</th>\n",
                                          "      <td>...</td>\n",
                                          "      <td>...</td>\n",
                                          "      <td>...</td>\n",
                                          "      <td>...</td>\n",
                                          "      <td>...</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>18540</th>\n",
                                          "      <td>9013</td>\n",
                                          "      <td>QLD</td>\n",
                                          "      <td>152.823141</td>\n",
                                          "      <td>-27.603479</td>\n",
                                          "      <td>31000</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>18541</th>\n",
                                          "      <td>9015</td>\n",
                                          "      <td>QLD</td>\n",
                                          "      <td>152.823141</td>\n",
                                          "      <td>-27.603479</td>\n",
                                          "      <td>31000</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>18542</th>\n",
                                          "      <td>9464</td>\n",
                                          "      <td>QLD</td>\n",
                                          "      <td>153.074982</td>\n",
                                          "      <td>-27.397055</td>\n",
                                          "      <td>31000</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>18543</th>\n",
                                          "      <td>9726</td>\n",
                                          "      <td>QLD</td>\n",
                                          "      <td>153.412197</td>\n",
                                          "      <td>-28.008783</td>\n",
                                          "      <td>33430</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>18544</th>\n",
                                          "      <td>9999</td>\n",
                                          "      <td>VIC</td>\n",
                                          "      <td>144.956776</td>\n",
                                          "      <td>-37.817403</td>\n",
                                          "      <td>24600</td>\n",
                                          "    </tr>\n",
                                          "  </tbody>\n",
                                          "</table>\n",
                                          "<p>3175 rows Ã— 5 columns</p>\n",
                                          "</div>"
                                    ],
                                    "text/plain": [
                                          "       postcode state        long        lat  lgacode\n",
                                          "0           200   ACT  149.119000 -35.277700    89399\n",
                                          "2           800    NT  130.836680 -12.458684    71150\n",
                                          "4           801    NT  130.836680 -12.458684    71000\n",
                                          "5           803    NT  130.745908 -12.433991    71000\n",
                                          "6           804    NT  130.873315 -12.428017    71000\n",
                                          "...         ...   ...         ...        ...      ...\n",
                                          "18540      9013   QLD  152.823141 -27.603479    31000\n",
                                          "18541      9015   QLD  152.823141 -27.603479    31000\n",
                                          "18542      9464   QLD  153.074982 -27.397055    31000\n",
                                          "18543      9726   QLD  153.412197 -28.008783    33430\n",
                                          "18544      9999   VIC  144.956776 -37.817403    24600\n",
                                          "\n",
                                          "[3175 rows x 5 columns]"
                                    ]
                              },
                              "execution_count": 6,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "postcode_lga_map = pd.read_csv(\"../data/raw/australian_postcodes.csv\")\n",
                        "\n",
                        "# Clean the data\n",
                        "postcode_lga_map = clean_postcode_lga_mapping(postcode_lga_map)\n",
                        "\n",
                        "# Display the data\n",
                        "postcode_lga_map"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "For the data on median/mean income and age of earners, as the data is in excel format, we did some extensive work to renaming the columns as well as selecting the correct rows that contain the number we want.\n",
                        "\n",
                        "There are LGA codes in Western Australia that do not have any values across all features that we're planning to use. Thus, we will impute the median age, income and mean income using the state's values. \n",
                        "\n",
                        "For the number of earners, we notice that there's a discrepancy in the total number of earners. In total, the number of earners in Western Australia is 1,585,093 whereas when summing up the number of earners across all LGA code in Western Australia, the number is 1,5815,061. This is a difference of 32 earners. We're not entirely sure why this discrepancy occurs but we will split this number in half for the 2 missing LGA code. Even though this is not a sound solution, we believe that imputing such number for only 2 entries doesn't affect the fraud probability predition significantly as well as we're not entirely sure if the consumers live in this LGA code."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/html": [
                                          "<div>\n",
                                          "<style scoped>\n",
                                          "    .dataframe tbody tr th:only-of-type {\n",
                                          "        vertical-align: middle;\n",
                                          "    }\n",
                                          "\n",
                                          "    .dataframe tbody tr th {\n",
                                          "        vertical-align: top;\n",
                                          "    }\n",
                                          "\n",
                                          "    .dataframe thead th {\n",
                                          "        text-align: right;\n",
                                          "    }\n",
                                          "</style>\n",
                                          "<table border=\"1\" class=\"dataframe\">\n",
                                          "  <thead>\n",
                                          "    <tr style=\"text-align: right;\">\n",
                                          "      <th></th>\n",
                                          "      <th>lga</th>\n",
                                          "      <th>median_age</th>\n",
                                          "      <th>median_income</th>\n",
                                          "      <th>mean_income</th>\n",
                                          "    </tr>\n",
                                          "  </thead>\n",
                                          "  <tbody>\n",
                                          "    <tr>\n",
                                          "      <th>0</th>\n",
                                          "      <td>10050</td>\n",
                                          "      <td>43</td>\n",
                                          "      <td>53392</td>\n",
                                          "      <td>62395</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>1</th>\n",
                                          "      <td>10180</td>\n",
                                          "      <td>43</td>\n",
                                          "      <td>48837</td>\n",
                                          "      <td>58514</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>2</th>\n",
                                          "      <td>10250</td>\n",
                                          "      <td>48</td>\n",
                                          "      <td>47527</td>\n",
                                          "      <td>60261</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>3</th>\n",
                                          "      <td>10300</td>\n",
                                          "      <td>43</td>\n",
                                          "      <td>49408</td>\n",
                                          "      <td>53342</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>4</th>\n",
                                          "      <td>10470</td>\n",
                                          "      <td>43</td>\n",
                                          "      <td>55986</td>\n",
                                          "      <td>64364</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>5</th>\n",
                                          "      <td>10500</td>\n",
                                          "      <td>38</td>\n",
                                          "      <td>55000</td>\n",
                                          "      <td>67148</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>6</th>\n",
                                          "      <td>10550</td>\n",
                                          "      <td>51</td>\n",
                                          "      <td>43532</td>\n",
                                          "      <td>51652</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>7</th>\n",
                                          "      <td>10600</td>\n",
                                          "      <td>50</td>\n",
                                          "      <td>41711</td>\n",
                                          "      <td>51346</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>8</th>\n",
                                          "      <td>10650</td>\n",
                                          "      <td>49</td>\n",
                                          "      <td>44099</td>\n",
                                          "      <td>50045</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>9</th>\n",
                                          "      <td>10750</td>\n",
                                          "      <td>39</td>\n",
                                          "      <td>58934</td>\n",
                                          "      <td>65892</td>\n",
                                          "    </tr>\n",
                                          "  </tbody>\n",
                                          "</table>\n",
                                          "</div>"
                                    ],
                                    "text/plain": [
                                          "     lga median_age  median_income  mean_income\n",
                                          "0  10050         43          53392        62395\n",
                                          "1  10180         43          48837        58514\n",
                                          "2  10250         48          47527        60261\n",
                                          "3  10300         43          49408        53342\n",
                                          "4  10470         43          55986        64364\n",
                                          "5  10500         38          55000        67148\n",
                                          "6  10550         51          43532        51652\n",
                                          "7  10600         50          41711        51346\n",
                                          "8  10650         49          44099        50045\n",
                                          "9  10750         39          58934        65892"
                                    ]
                              },
                              "execution_count": 7,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "income_df = pd.read_excel(\"../data/raw/income_data.xlsx\", sheet_name = \"Table 2.5\", skiprows = 5, skipfooter = 5)\n",
                        "\n",
                        "income_df = preprocess_income_df(income_df)\n",
                        "income_df.head(10)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Merging the income data with the postcode data."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 8,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Shape of postcode data before the merge: (3175, 5)\n",
                                    "Shape of postcode data after the merge: (3175, 9)\n"
                              ]
                        }
                  ],
                  "source": [
                        "print(f\"Shape of postcode data before the merge: {postcode_lga_map.shape}\")\n",
                        "postcode_info = postcode_lga_map.merge(income_df, left_on='lgacode', right_on='lga',\n",
                        "                                       how = \"left\" )\n",
                        "print(f\"Shape of postcode data after the merge: {postcode_info.shape}\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "We also need to check that if there are any postcode with LGA code that is not in the income data"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/html": [
                                          "<div>\n",
                                          "<style scoped>\n",
                                          "    .dataframe tbody tr th:only-of-type {\n",
                                          "        vertical-align: middle;\n",
                                          "    }\n",
                                          "\n",
                                          "    .dataframe tbody tr th {\n",
                                          "        vertical-align: top;\n",
                                          "    }\n",
                                          "\n",
                                          "    .dataframe thead th {\n",
                                          "        text-align: right;\n",
                                          "    }\n",
                                          "</style>\n",
                                          "<table border=\"1\" class=\"dataframe\">\n",
                                          "  <thead>\n",
                                          "    <tr style=\"text-align: right;\">\n",
                                          "      <th></th>\n",
                                          "      <th>postcode</th>\n",
                                          "      <th>state</th>\n",
                                          "      <th>long</th>\n",
                                          "      <th>lat</th>\n",
                                          "      <th>lgacode</th>\n",
                                          "      <th>lga</th>\n",
                                          "      <th>median_age</th>\n",
                                          "      <th>median_income</th>\n",
                                          "      <th>mean_income</th>\n",
                                          "    </tr>\n",
                                          "  </thead>\n",
                                          "  <tbody>\n",
                                          "    <tr>\n",
                                          "      <th>734</th>\n",
                                          "      <td>2540</td>\n",
                                          "      <td>NSW</td>\n",
                                          "      <td>150.578900</td>\n",
                                          "      <td>-34.828200</td>\n",
                                          "      <td>99399</td>\n",
                                          "      <td>NaN</td>\n",
                                          "      <td>NaN</td>\n",
                                          "      <td>NaN</td>\n",
                                          "      <td>NaN</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>979</th>\n",
                                          "      <td>2899</td>\n",
                                          "      <td>NSW</td>\n",
                                          "      <td>146.928783</td>\n",
                                          "      <td>-36.084231</td>\n",
                                          "      <td>99399</td>\n",
                                          "      <td>NaN</td>\n",
                                          "      <td>NaN</td>\n",
                                          "      <td>NaN</td>\n",
                                          "      <td>NaN</td>\n",
                                          "    </tr>\n",
                                          "  </tbody>\n",
                                          "</table>\n",
                                          "</div>"
                                    ],
                                    "text/plain": [
                                          "     postcode state        long        lat lgacode  lga median_age  \\\n",
                                          "734      2540   NSW  150.578900 -34.828200   99399  NaN        NaN   \n",
                                          "979      2899   NSW  146.928783 -36.084231   99399  NaN        NaN   \n",
                                          "\n",
                                          "     median_income  mean_income  \n",
                                          "734            NaN          NaN  \n",
                                          "979            NaN          NaN  "
                                    ]
                              },
                              "execution_count": 9,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "postcode_info[postcode_info.lga.isnull()]"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "We can see that there are 2 postcode that does not appear in the income data. We will follow the same approach, using K-Nearest Neighbour, that we did previously to compute these value."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "postcode_info = impute_income_metrics(postcode_info)\n",
                        "postcode_info = postcode_info.drop(columns='lga')"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "The ABS's **Personal Fraud** data have multiple tables, in which we will use Table 4a and Table 4b as it contains the percentage of individual experienced personal fraud and respective Relative Standard Error (RSE) for each state, respectively. We will use the rate from 2021 to 2022 to match our the date range of the data we have one the transactions."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 11,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/html": [
                                          "<div>\n",
                                          "<style scoped>\n",
                                          "    .dataframe tbody tr th:only-of-type {\n",
                                          "        vertical-align: middle;\n",
                                          "    }\n",
                                          "\n",
                                          "    .dataframe tbody tr th {\n",
                                          "        vertical-align: top;\n",
                                          "    }\n",
                                          "\n",
                                          "    .dataframe thead th {\n",
                                          "        text-align: right;\n",
                                          "    }\n",
                                          "</style>\n",
                                          "<table border=\"1\" class=\"dataframe\">\n",
                                          "  <thead>\n",
                                          "    <tr style=\"text-align: right;\">\n",
                                          "      <th></th>\n",
                                          "      <th>state</th>\n",
                                          "      <th>victimisation_rate</th>\n",
                                          "      <th>rse_percent</th>\n",
                                          "    </tr>\n",
                                          "  </thead>\n",
                                          "  <tbody>\n",
                                          "    <tr>\n",
                                          "      <th>0</th>\n",
                                          "      <td>NSW</td>\n",
                                          "      <td>10.7</td>\n",
                                          "      <td>4.3</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>1</th>\n",
                                          "      <td>VIC</td>\n",
                                          "      <td>11.2</td>\n",
                                          "      <td>5.5</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>2</th>\n",
                                          "      <td>QLD</td>\n",
                                          "      <td>10.4</td>\n",
                                          "      <td>5.3</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>3</th>\n",
                                          "      <td>SA</td>\n",
                                          "      <td>10.1</td>\n",
                                          "      <td>6.0</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>4</th>\n",
                                          "      <td>WA</td>\n",
                                          "      <td>11.3</td>\n",
                                          "      <td>7.1</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>5</th>\n",
                                          "      <td>TAS</td>\n",
                                          "      <td>9.8</td>\n",
                                          "      <td>6.7</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>6</th>\n",
                                          "      <td>NT</td>\n",
                                          "      <td>10.0</td>\n",
                                          "      <td>13.7</td>\n",
                                          "    </tr>\n",
                                          "    <tr>\n",
                                          "      <th>7</th>\n",
                                          "      <td>ACT</td>\n",
                                          "      <td>11.7</td>\n",
                                          "      <td>9.0</td>\n",
                                          "    </tr>\n",
                                          "  </tbody>\n",
                                          "</table>\n",
                                          "</div>"
                                    ],
                                    "text/plain": [
                                          "  state  victimisation_rate  rse_percent\n",
                                          "0   NSW                10.7          4.3\n",
                                          "1   VIC                11.2          5.5\n",
                                          "2   QLD                10.4          5.3\n",
                                          "3    SA                10.1          6.0\n",
                                          "4    WA                11.3          7.1\n",
                                          "5   TAS                 9.8          6.7\n",
                                          "6    NT                10.0         13.7\n",
                                          "7   ACT                11.7          9.0"
                                    ]
                              },
                              "execution_count": 11,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "pf_df = process_fp_data(path=\"../data/raw/personal_fraud.xlsx\")\n",
                        "pf_df"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## Main Dataset\n",
                        "\n",
                        "The system use `user_id` as a key for identifying customer in transactions record and fraud probability tables. However, they also have a key-value map of `user_id` and `consumer_id`. We will use `consumer_id` as the only ID for customer. Thus, we will map `user_id` from each table to `consumer_id` and drop the former."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 12,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "                                                                                \r"
                              ]
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "<table border='1'>\n",
                                          "<tr><th>user_id</th><th>consumer_id</th></tr>\n",
                                          "<tr><td>1</td><td>1195503</td></tr>\n",
                                          "<tr><td>2</td><td>179208</td></tr>\n",
                                          "<tr><td>3</td><td>1194530</td></tr>\n",
                                          "<tr><td>4</td><td>154128</td></tr>\n",
                                          "<tr><td>5</td><td>712975</td></tr>\n",
                                          "</table>\n"
                                    ],
                                    "text/plain": [
                                          "+-------+-----------+\n",
                                          "|user_id|consumer_id|\n",
                                          "+-------+-----------+\n",
                                          "|      1|    1195503|\n",
                                          "|      2|     179208|\n",
                                          "|      3|    1194530|\n",
                                          "|      4|     154128|\n",
                                          "|      5|     712975|\n",
                                          "+-------+-----------+"
                                    ]
                              },
                              "execution_count": 12,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "# Load consumer user details -> a key:value map for user_id to consumer_id\n",
                        "consumer_user_map = spark.read.parquet(f\"{raw_path}/tables/consumer_user_details.parquet\")\n",
                        "consumer_user_map.limit(5) # Preview"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 13,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "+-------+--------------+-----------------+\n",
                                    "|user_id|order_datetime|fraud_probability|\n",
                                    "+-------+--------------+-----------------+\n",
                                    "|   6228|    2021-12-19| 97.6298077657765|\n",
                                    "|  21419|    2021-12-10|99.24738020302328|\n",
                                    "|   5606|    2021-10-17|84.05825045251777|\n",
                                    "|   3101|    2021-04-17|91.42192091901347|\n",
                                    "|  22239|    2021-10-19|94.70342477508035|\n",
                                    "+-------+--------------+-----------------+\n",
                                    "only showing top 5 rows\n",
                                    "\n",
                                    "The dataset count is  34864\n",
                                    "+--------------+------------------+-----------+\n",
                                    "|order_datetime| fraud_probability|consumer_id|\n",
                                    "+--------------+------------------+-----------+\n",
                                    "|    2022-02-20| 9.805431136520959|    1195503|\n",
                                    "|    2021-08-30| 9.599513915425788|     179208|\n",
                                    "|    2021-09-25|10.069850934775245|     179208|\n",
                                    "|    2021-11-03| 8.300636455314633|    1194530|\n",
                                    "|    2021-10-09| 9.633302411090419|     154128|\n",
                                    "+--------------+------------------+-----------+\n",
                                    "only showing top 5 rows\n",
                                    "\n",
                                    "The dataset count is  34864\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Load consumer fraud rate dataset\n",
                        "consumer_fraud_rate = spark.read.csv(f\"{raw_path}/tables/consumer_fraud_probability.csv\", header=True, inferSchema=True)\n",
                        "consumer_fraud_rate.show(5)\n",
                        "get_dataset_count(consumer_fraud_rate)\n",
                        "\n",
                        "# Replace all user_id with unique consumer_id\n",
                        "consumer_fraud_rate = replace_id(consumer_user_map, consumer_fraud_rate)\n",
                        "consumer_fraud_rate.show(5)\n",
                        "\n",
                        "# Check to make sure no rows were lost on the inner join\n",
                        "get_dataset_count(consumer_fraud_rate)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "We see that there is no change in the number of entries upon an inner join."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 15,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "20128"
                                    ]
                              },
                              "execution_count": 15,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "consumer_fraud_rate.groupBy('consumer_id').agg(F.avg(\"fraud_probability\").alias('avg_fp')).count()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 14,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "                                                                                \r"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "The dataset count is  14195505\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "[Stage 25:=================================>                     (37 + 20) / 60]\r"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "The dataset count is  14195505\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "                                                                                \r"
                              ]
                        }
                  ],
                  "source": [
                        "# Load all the transaction data \n",
                        "transaction_p1 = spark.read.parquet(f\"{raw_path}/tables/transactions_20210228_20210827_snapshot\")\n",
                        "transaction_p2 = spark.read.parquet(f\"{raw_path}/tables/transactions_20210828_20220227_snapshot\")\n",
                        "transaction_p3 = spark.read.parquet(f\"{raw_path}/tables/transactions_20220228_20220828_snapshot\")\n",
                        "\n",
                        "# Combine the datasets\n",
                        "transaction_records = reduce(DataFrame.unionAll, [transaction_p1, transaction_p2, transaction_p3])\n",
                        "get_dataset_count(transaction_records)\n",
                        "\n",
                        "# Replace user_id with consumer_id after combining\n",
                        "transaction_records = replace_id(consumer_user_map, transaction_records)\n",
                        "\n",
                        "# Check to make sure no rows were lost on the inner join\n",
                        "get_dataset_count(transaction_records)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## Cleaning"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Now that replacing `user_id` to `consumer_id` is done, we will load all other data and clean them altogether. We start off with dropping duplicates from the consumer fraud probability data"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 15,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Number of entries before dropping duplicates: 34864\n",
                                    "Number of entries after dropping duplicates: 34765\n"
                              ]
                        }
                  ],
                  "source": [
                        "print(f\"Number of entries before dropping duplicates: {consumer_fraud_rate.count()}\")\n",
                        "consumer_fraud_rate = consumer_fraud_rate.dropDuplicates()\n",
                        "print(f\"Number of entries after dropping duplicates: {consumer_fraud_rate.count()}\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "We can see that around 0.28% of the entries are duplicates.\n",
                        "\n",
                        "Doing the same thing for the transactions data."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 16,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Number of entries before dropping duplicates: 14195505\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:26:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "[Stage 46:=====================================================>  (21 + 1) / 22]\r"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Number of entries after dropping duplicates: 14195505\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "                                                                                \r"
                              ]
                        }
                  ],
                  "source": [
                        "print(f\"Number of entries before dropping duplicates: {transaction_records.count()}\")\n",
                        "transaction_records = transaction_records.dropDuplicates()\n",
                        "print(f\"Number of entries after dropping duplicates: {transaction_records.count()}\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "There are no duplicates in the transactions data. Next, we will load the merchant fraud rate and repeat the same process."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 17,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "+------------+--------------+------------------+\n",
                                    "|merchant_abn|order_datetime| fraud_probability|\n",
                                    "+------------+--------------+------------------+\n",
                                    "| 19492220327|    2021-11-28|44.403658647495355|\n",
                                    "| 31334588839|    2021-10-02| 42.75530083865367|\n",
                                    "| 19492220327|    2021-12-22|38.867790051131095|\n",
                                    "| 82999039227|    2021-12-19|  94.1347004808891|\n",
                                    "| 90918180829|    2021-09-02| 43.32551731714902|\n",
                                    "+------------+--------------+------------------+\n",
                                    "only showing top 5 rows\n",
                                    "\n",
                                    "The dataset count is  114\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Load consumer fraud rate dataset\n",
                        "merchant_fraud_rate = spark.read.csv(f\"{raw_path}/tables/merchant_fraud_probability.csv\", header=True, inferSchema=True)\n",
                        "merchant_fraud_rate.show(5)\n",
                        "get_dataset_count(merchant_fraud_rate)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Removing any duplicates existing in the data"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 18,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Number of entries before dropping duplicates: 114\n",
                                    "Number of entries after dropping duplicates: 114\n"
                              ]
                        }
                  ],
                  "source": [
                        "print(f\"Number of entries before dropping duplicates: {merchant_fraud_rate.count()}\")\n",
                        "merchant_fraud_rate = merchant_fraud_rate.dropDuplicates()\n",
                        "print(f\"Number of entries after dropping duplicates: {merchant_fraud_rate.count()}\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Cleaning `tbl_merchants.parquet`. The feature `tags` is a string that represents either a tuple or a list, containing 3 elements:\n",
                        "* Items that are being sold\n",
                        "* Revenue levels\n",
                        "* Commission rate\n",
                        "\n",
                        "Each elements either a list, a tuple, or a combination of both (e.g starts with `[` and ends with `)` and vice versa). These inconsistencies are mostly due to human errors. Thus, we need to take into account these consistent when splitting the values of the feature `tags` into separate columns"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 19,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "+------------------------------------+-----------------------------------------------------------------------------------------------------------------+------------+\n",
                                    "|name                                |tags                                                                                                             |merchant_abn|\n",
                                    "+------------------------------------+-----------------------------------------------------------------------------------------------------------------+------------+\n",
                                    "|Felis Limited                       |((furniture, home furnishings and equipment shops, and manufacturers, except appliances), (e), (take rate: 0.18))|10023283211 |\n",
                                    "|Arcu Ac Orci Corporation            |([cable, satellite, and otHer pay television and radio services], [b], [take rate: 4.22])                        |10142254217 |\n",
                                    "|Nunc Sed Company                    |([jewelry, watch, clock, and silverware shops], [b], [take rate: 4.40])                                          |10165489824 |\n",
                                    "|Ultricies Dignissim Lacus Foundation|([wAtch, clock, and jewelry repair shops], [b], [take rate: 3.29])                                               |10187291046 |\n",
                                    "|Enim Condimentum PC                 |([music shops - musical instruments, pianos, and sheet music], [a], [take rate: 6.33])                           |10192359162 |\n",
                                    "+------------------------------------+-----------------------------------------------------------------------------------------------------------------+------------+\n",
                                    "only showing top 5 rows\n",
                                    "\n",
                                    "Before: \n",
                                    "The dataset count is  4026\n",
                                    "After: \n",
                                    "The dataset count is  4026\n",
                                    "+------------------------------------+------------+-------------------------------------------------------------------------------------+-------------+---------+\n",
                                    "|name                                |merchant_abn|category                                                                             |revenue_level|take_rate|\n",
                                    "+------------------------------------+------------+-------------------------------------------------------------------------------------+-------------+---------+\n",
                                    "|Felis Limited                       |10023283211 |furniture, home furnishings and equipment shops, and manufacturers, except appliances|e            |0.18     |\n",
                                    "|Arcu Ac Orci Corporation            |10142254217 |cable, satellite, and other pay television and radio services                        |b            |4.22     |\n",
                                    "|Nunc Sed Company                    |10165489824 |jewelry, watch, clock, and silverware shops                                          |b            |4.4      |\n",
                                    "|Ultricies Dignissim Lacus Foundation|10187291046 |watch, clock, and jewelry repair shops                                               |b            |3.29     |\n",
                                    "|Enim Condimentum PC                 |10192359162 |music shops - musical instruments, pianos, and sheet music                           |a            |6.33     |\n",
                                    "+------------------------------------+------------+-------------------------------------------------------------------------------------+-------------+---------+\n",
                                    "only showing top 5 rows\n",
                                    "\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Load merchant's info\n",
                        "merchant_info = spark.read.parquet(f\"{raw_path}/tables/tbl_merchants.parquet\")\n",
                        "merchant_info.show(5, truncate=False)\n",
                        "\n",
                        "# Clean the data\n",
                        "merchant_info = clean_merchant_details(merchant_info)\n",
                        "merchant_info.show(5, truncate=False)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Removing any duplicated merchants."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 20,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Number of entries before dropping duplicates: 4026\n",
                                    "Number of entries after dropping duplicates: 4026\n"
                              ]
                        }
                  ],
                  "source": [
                        "print(f\"Number of entries before dropping duplicates: {merchant_info.count()}\")\n",
                        "merchant_info = merchant_info.dropDuplicates()\n",
                        "print(f\"Number of entries after dropping duplicates: {merchant_info.count()}\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "The data on consumer's basic information is a single column that contains the consumer's name, address, state, postcode, gender, and their unqiue consumer ID, each separated by \"`|`\". Thus, we will need to split these into individual columns. Based on the `README.md` for the data, we will only keep the consumer's name, state, postcode, gender, and consumer ID as the addresses are fake."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 16,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "+---------------------------------------------------------------------+\n",
                                    "|name|address|state|postcode|gender|consumer_id                       |\n",
                                    "+---------------------------------------------------------------------+\n",
                                    "|Yolanda Williams|413 Haney Gardens Apt. 742|WA|6935|Female|1195503   |\n",
                                    "|Mary Smith|3764 Amber Oval|NSW|2782|Female|179208                    |\n",
                                    "|Jill Jones MD|40693 Henry Greens|NT|862|Female|1194530               |\n",
                                    "|Lindsay Jimenez|00653 Davenport Crossroad|NSW|2780|Female|154128     |\n",
                                    "|Rebecca Blanchard|9271 Michael Manors Suite 651|WA|6355|Female|712975|\n",
                                    "+---------------------------------------------------------------------+\n",
                                    "only showing top 5 rows\n",
                                    "\n",
                                    "Before: \n",
                                    "The dataset count is  499999\n",
                                    "After: \n",
                                    "The dataset count is  499999\n",
                                    "+-----------------+-----------+------+-----+--------+\n",
                                    "|name             |consumer_id|gender|state|postcode|\n",
                                    "+-----------------+-----------+------+-----+--------+\n",
                                    "|Yolanda Williams |1195503    |Female|WA   |6935    |\n",
                                    "|Mary Smith       |179208     |Female|NSW  |2782    |\n",
                                    "|Jill Jones MD    |1194530    |Female|NT   |862     |\n",
                                    "|Lindsay Jimenez  |154128     |Female|NSW  |2780    |\n",
                                    "|Rebecca Blanchard|712975     |Female|WA   |6355    |\n",
                                    "+-----------------+-----------+------+-----+--------+\n",
                                    "only showing top 5 rows\n",
                                    "\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Load consumer info's\n",
                        "consumer_info = spark.read.csv(f\"{raw_path}/tables/tbl_consumer.csv\", header=True, inferSchema=True)\n",
                        "consumer_info.show(5, truncate=False)\n",
                        "\n",
                        "# Clean the data\n",
                        "consumer_info = clean_consumer_details(consumer_info)\n",
                        "consumer_info.show(5, truncate=False)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Removing any duplicated consumers."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 22,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Number of entries before dropping duplicates: 499999\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "[Stage 96:==============>                                           (2 + 6) / 8]\r"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Number of entries after dropping duplicates: 499999\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "                                                                                \r"
                              ]
                        }
                  ],
                  "source": [
                        "print(f\"Number of entries before dropping duplicates: {consumer_info.count()}\")\n",
                        "consumer_info = consumer_info.dropDuplicates()\n",
                        "print(f\"Number of entries after dropping duplicates: {consumer_info.count()}\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "For all data (transactions, merchant and consumer fraud probability), we will need to ensure that the datetime of all dataset with such column is within the specified range (labeled on the name of the intial downloaded file)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 23,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:27:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "[Stage 112:=================================================>     (19 + 2) / 21]\r"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Starting entries: 14195505 \n",
                                    "Final entries: 12544270\n",
                                    "Net change (%): 11.63 \n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "                                                                                \r"
                              ]
                        }
                  ],
                  "source": [
                        "transaction_records = ensure_datetime_range(transaction_records, \"2021-03-01\", \"2022-08-28\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 24,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Starting entries: 114 \n",
                                    "Final entries: 114\n",
                                    "Net change (%): 0.0 \n"
                              ]
                        }
                  ],
                  "source": [
                        "merchant_fraud_rate = ensure_datetime_range(merchant_fraud_rate, \"2021-03-01\", \"2022-08-28\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 25,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Starting entries: 34765 \n",
                                    "Final entries: 34747\n",
                                    "Net change (%): 0.05 \n"
                              ]
                        }
                  ],
                  "source": [
                        "consumer_fraud_rate = ensure_datetime_range(consumer_fraud_rate, \"2021-03-01\", \"2022-08-28\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Next, we check for any existing null values across all dataset."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 26,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "+----------------------------+-------------------------------+-------------------------+\n",
                                    "|order_datetime_missing_count|fraud_probability_missing_count|consumer_id_missing_count|\n",
                                    "+----------------------------+-------------------------------+-------------------------+\n",
                                    "|                           0|                              0|                        0|\n",
                                    "+----------------------------+-------------------------------+-------------------------+\n",
                                    "\n",
                                    "+--------------------------+----------------------------+-------------------------------+\n",
                                    "|merchant_abn_missing_count|order_datetime_missing_count|fraud_probability_missing_count|\n",
                                    "+--------------------------+----------------------------+-------------------------------+\n",
                                    "|                         0|                           0|                              0|\n",
                                    "+--------------------------+----------------------------+-------------------------------+\n",
                                    "\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "                                                                                \r"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "+------------------+-------------------------+--------------------+-------------------+----------------------+\n",
                                    "|name_missing_count|consumer_id_missing_count|gender_missing_count|state_missing_count|postcode_missing_count|\n",
                                    "+------------------+-------------------------+--------------------+-------------------+----------------------+\n",
                                    "|                 0|                        0|                   0|                  0|                     0|\n",
                                    "+------------------+-------------------------+--------------------+-------------------+----------------------+\n",
                                    "\n",
                                    "+------------------+--------------------------+----------------------+---------------------------+-----------------------+\n",
                                    "|name_missing_count|merchant_abn_missing_count|category_missing_count|revenue_level_missing_count|take_rate_missing_count|\n",
                                    "+------------------+--------------------------+----------------------+---------------------------+-----------------------+\n",
                                    "|                 0|                         0|                     0|                          0|                      0|\n",
                                    "+------------------+--------------------------+----------------------+---------------------------+-----------------------+\n",
                                    "\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "[Stage 170:====================================>                  (14 + 7) / 21]\r"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "+--------------------------+--------------------------+----------------------+----------------------------+-------------------------+\n",
                                    "|merchant_abn_missing_count|dollar_value_missing_count|order_id_missing_count|order_datetime_missing_count|consumer_id_missing_count|\n",
                                    "+--------------------------+--------------------------+----------------------+----------------------------+-------------------------+\n",
                                    "|                         0|                         0|                     0|                           0|                        0|\n",
                                    "+--------------------------+--------------------------+----------------------+----------------------------+-------------------------+\n",
                                    "\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "                                                                                \r"
                              ]
                        }
                  ],
                  "source": [
                        "calculate_missing_values(consumer_fraud_rate)\n",
                        "calculate_missing_values(merchant_fraud_rate)\n",
                        "calculate_missing_values(consumer_info)\n",
                        "calculate_missing_values(merchant_info)\n",
                        "calculate_missing_values(transaction_records)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Currently, there are no mising values after we do some cleaning. We will come back to this after we merged the data together."
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "# Load"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 27,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "landing_directory = \"../data/curated\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 28,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "24/09/29 15:28:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
                                    "                                                                                \r"
                              ]
                        }
                  ],
                  "source": [
                        "# Main dataset\n",
                        "consumer_fraud_rate.write.parquet(f\"{landing_directory}/consumer_fp.parquet\", mode = 'overwrite')\n",
                        "merchant_fraud_rate.write.parquet(f\"{landing_directory}/merchant_fp.parquet\", mode = 'overwrite')\n",
                        "transaction_records.write.parquet(f\"{landing_directory}/transactions.parquet\", mode = 'overwrite')\n",
                        "merchant_info.write.parquet(f\"{landing_directory}/merchant_info.parquet\", mode = 'overwrite')\n",
                        "consumer_info.write.parquet(f\"{landing_directory}/consumer_info.parquet\", mode = 'overwrite')"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 29,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# External dataset\n",
                        "postcode_info.to_csv(\"../data/curated/postcode_info.csv\")\n",
                        "pf_df.to_csv(\"../data/curated/personal_fraud.csv\")"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "Python 3",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.8.10"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 2
}
